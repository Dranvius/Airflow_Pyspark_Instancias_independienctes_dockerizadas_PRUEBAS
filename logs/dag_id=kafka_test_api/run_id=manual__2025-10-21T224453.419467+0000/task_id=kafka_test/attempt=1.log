{"timestamp":"2025-10-21T22:44:55.951208","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-10-21T22:44:55.954780","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/KAFKA_AIRFLOW_PYSPARK.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-10-21T22:44:57.189251Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-21T22:44:57.215521Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-21T22:44:57.216166Z","level":"info","event":"Current task name:kafka_test","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-21T22:44:57.216734Z","level":"info","event":"Dag name:kafka_test_api","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-21T22:44:57.192325","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-10-21T22:44:57.246240","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-10-21T22:44:57.252914","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.7.0,org.postgresql:postgresql:42.7.3 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:44:58.098404","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.744031","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.744349","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.744643","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.744806","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.744922","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.745098","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.745277","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.745492","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.745687","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.745901","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.746097","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.746301","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.746538","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.746776","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.746974","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.747183","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.747363","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.747605","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.747858","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.748103","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.748317","level":"info","event":"primaryResource         file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.748511","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.748719","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.748864","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.750026","level":"info","event":"packages                org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.7.0,org.postgresql:postgresql:42.7.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.750433","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.750699","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.750915","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.751596","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.752337","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.752626","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.753163","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.753505","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.754494","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:00.755013","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:01.376043","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:01.643210","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:01.643594","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:01.662230","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:01.663197","level":"info","event":"org.apache.kafka#kafka-clients added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:01.664271","level":"info","event":"org.postgresql#postgresql added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:01.671569","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-2c371998-3aa7-42cb-b187-c1d38bace74e;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:01.672069","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:02.360266","level":"info","event":"found org.apache.spark#spark-sql-kafka-0-10_2.13;3.5.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:02.541403","level":"info","event":"found org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.5.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:02.680965","level":"info","event":"found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:02.805048","level":"info","event":"found org.apache.hadoop#hadoop-client-api;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:02.896635","level":"info","event":"found org.xerial.snappy#snappy-java;1.1.10.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:02.960104","level":"info","event":"found org.slf4j#slf4j-api;2.0.7 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.031040","level":"info","event":"found commons-logging#commons-logging;1.1.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.128661","level":"info","event":"found com.google.code.findbugs#jsr305;3.0.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.255077","level":"info","event":"found org.scala-lang.modules#scala-parallel-collections_2.13;1.0.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.374062","level":"info","event":"found org.apache.commons#commons-pool2;2.11.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.431359","level":"info","event":"found org.apache.kafka#kafka-clients;3.7.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.522799","level":"info","event":"found com.github.luben#zstd-jni;1.5.5-6 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.571464","level":"info","event":"found org.lz4#lz4-java;1.8.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.634288","level":"info","event":"found org.xerial.snappy#snappy-java;1.1.10.5 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.674235","level":"info","event":"found org.postgresql#postgresql;42.7.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:03.706812","level":"info","event":"found org.checkerframework#checker-qual;3.42.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:04.872014","level":"info","event":"downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:04.983694","level":"info","event":"[SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (1139ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:05.025964","level":"info","event":"downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:05.633638","level":"info","event":"[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (644ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:05.703942","level":"info","event":"downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.5.5-6/zstd-jni-1.5.5-6.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:07.648933","level":"info","event":"[SUCCESSFUL ] com.github.luben#zstd-jni;1.5.5-6!zstd-jni.jar (1996ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:07.743341","level":"info","event":"downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:07.940820","level":"info","event":"[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (291ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:07.995445","level":"info","event":"downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.448771","level":"info","event":"[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.5!snappy-java.jar(bundle) (504ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.512312","level":"info","event":"downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.42.0/checker-qual-3.42.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.627474","level":"info","event":"[SUCCESSFUL ] org.checkerframework#checker-qual;3.42.0!checker-qual.jar (173ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.628645","level":"info","event":":: resolution report :: resolve 2097ms :: artifacts dl 4860ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.629010","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.632940","level":"info","event":"com.github.luben#zstd-jni;1.5.5-6 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.633303","level":"info","event":"com.google.code.findbugs#jsr305;3.0.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.634012","level":"info","event":"commons-logging#commons-logging;1.1.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.634390","level":"info","event":"org.apache.commons#commons-pool2;2.11.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.634625","level":"info","event":"org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.634843","level":"info","event":"org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.635373","level":"info","event":"org.apache.kafka#kafka-clients;3.7.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.635598","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.13;3.5.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.635851","level":"info","event":"org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.5.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.636442","level":"info","event":"org.checkerframework#checker-qual;3.42.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.636759","level":"info","event":"org.lz4#lz4-java;1.8.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.636947","level":"info","event":"org.postgresql#postgresql;42.7.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.637146","level":"info","event":"org.scala-lang.modules#scala-parallel-collections_2.13;1.0.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.637311","level":"info","event":"org.slf4j#slf4j-api;2.0.7 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.637483","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.5 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.637688","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.637846","level":"info","event":"org.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.7.0] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.638012","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.3 by [org.xerial.snappy#snappy-java;1.1.10.5] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.638177","level":"info","event":"org.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.638357","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.638526","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.638678","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.638889","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.639204","level":"info","event":"|      default     |   18  |   0   |   0   |   3   ||   15  |   6   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.639530","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.671647","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-2c371998-3aa7-42cb-b187-c1d38bace74e","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:08.672120","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:09.581186","level":"info","event":"15 artifacts copied, 0 already retrieved (68205kB/909ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:10.423481","level":"info","event":"25/10/21 22:45:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.463479","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.465223","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.475521","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.475919","level":"info","event":"file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.476144","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar,file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar,file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar,file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar,file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar,file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar,file:///home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.480878","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.481232","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.481458","level":"info","event":"(spark.app.submitTime,1761086711318)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.481621","level":"info","event":"(spark.files,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.481772","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.481921","level":"info","event":"(spark.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.482069","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.482232","level":"info","event":"(spark.repl.local.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.482402","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.482573","level":"info","event":"(spark.submit.pyFiles,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.492888","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.493378","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.493697","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.493965","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.494326","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.494629","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.494968","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.495486","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.495808","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.497115","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.497417","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.497653","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.497870","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.498195","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.498423","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.498757","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.509466","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:11.510249","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:18.055374","level":"info","event":"INFO:KafkaETL:=== Iniciando SparkSession ===","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:21.559478","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:21.590541","level":"info","event":"25/10/21 22:45:21 INFO SparkContext: Running Spark version 4.0.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:21.610505","level":"info","event":"25/10/21 22:45:21 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:21.628982","level":"info","event":"25/10/21 22:45:21 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:21.768588","level":"info","event":"25/10/21 22:45:21 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:21.773379","level":"info","event":"25/10/21 22:45:21 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:21.783234","level":"info","event":"25/10/21 22:45:21 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:21.785732","level":"info","event":"25/10/21 22:45:21 INFO SparkContext: Submitted application: KafkaETL_Batch","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:22.041878","level":"info","event":"25/10/21 22:45:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:22.065080","level":"info","event":"25/10/21 22:45:22 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:22.092324","level":"info","event":"25/10/21 22:45:22 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:22.326472","level":"info","event":"25/10/21 22:45:22 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:22.330552","level":"info","event":"25/10/21 22:45:22 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:22.331929","level":"info","event":"25/10/21 22:45:22 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:22.333261","level":"info","event":"25/10/21 22:45:22 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:22.342661","level":"info","event":"25/10/21 22:45:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:23.539511","level":"info","event":"25/10/21 22:45:23 INFO Utils: Successfully started service 'sparkDriver' on port 46193.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:23.733474","level":"info","event":"25/10/21 22:45:23 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:23.839302","level":"info","event":"25/10/21 22:45:23 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:23.903286","level":"info","event":"25/10/21 22:45:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:23.908231","level":"info","event":"25/10/21 22:45:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:23.922779","level":"info","event":"25/10/21 22:45:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:24.018687","level":"info","event":"25/10/21 22:45:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-856ac4ba-e003-467e-9b59-b72fc4ff6d03","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:24.080219","level":"info","event":"25/10/21 22:45:24 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:24.622904","level":"info","event":"25/10/21 22:45:24 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:24.908047","level":"info","event":"25/10/21 22:45:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.077937","level":"info","event":"25/10/21 22:45:25 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.320973","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar at spark://2bd63b47b915:46193/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.322174","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar at spark://2bd63b47b915:46193/jars/org.apache.kafka_kafka-clients-3.7.0.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.323263","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar at spark://2bd63b47b915:46193/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.326318","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar at spark://2bd63b47b915:46193/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.331395","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar at spark://2bd63b47b915:46193/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.359512","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://2bd63b47b915:46193/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.359850","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://2bd63b47b915:46193/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.360059","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://2bd63b47b915:46193/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.360294","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://2bd63b47b915:46193/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.360492","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://2bd63b47b915:46193/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.360781","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar at spark://2bd63b47b915:46193/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.361672","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar at spark://2bd63b47b915:46193/jars/com.github.luben_zstd-jni-1.5.5-6.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.363186","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://2bd63b47b915:46193/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.376324","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar at spark://2bd63b47b915:46193/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.377432","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://2bd63b47b915:46193/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.426848","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar at spark://2bd63b47b915:46193/files/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.440753","level":"info","event":"25/10/21 22:45:25 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.523356","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar at spark://2bd63b47b915:46193/files/org.apache.kafka_kafka-clients-3.7.0.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.523705","level":"info","event":"25/10/21 22:45:25 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.apache.kafka_kafka-clients-3.7.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.589318","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar at spark://2bd63b47b915:46193/files/org.postgresql_postgresql-42.7.3.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.589634","level":"info","event":"25/10/21 22:45:25 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.postgresql_postgresql-42.7.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.618746","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar at spark://2bd63b47b915:46193/files/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.620340","level":"info","event":"25/10/21 22:45:25 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.658103","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar at spark://2bd63b47b915:46193/files/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.658595","level":"info","event":"25/10/21 22:45:25 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.698237","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://2bd63b47b915:46193/files/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.698793","level":"info","event":"25/10/21 22:45:25 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.740411","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://2bd63b47b915:46193/files/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.746357","level":"info","event":"25/10/21 22:45:25 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.795284","level":"info","event":"25/10/21 22:45:25 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://2bd63b47b915:46193/files/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:25.796111","level":"info","event":"25/10/21 22:45:25 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:26.137420","level":"info","event":"25/10/21 22:45:26 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://2bd63b47b915:46193/files/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:26.142315","level":"info","event":"25/10/21 22:45:26 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.293320","level":"info","event":"25/10/21 22:45:27 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://2bd63b47b915:46193/files/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.294007","level":"info","event":"25/10/21 22:45:27 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.327922","level":"info","event":"25/10/21 22:45:27 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar at spark://2bd63b47b915:46193/files/commons-logging_commons-logging-1.1.3.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.329522","level":"info","event":"25/10/21 22:45:27 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.358202","level":"info","event":"25/10/21 22:45:27 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar at spark://2bd63b47b915:46193/files/com.github.luben_zstd-jni-1.5.5-6.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.360401","level":"info","event":"25/10/21 22:45:27 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/com.github.luben_zstd-jni-1.5.5-6.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.409409","level":"info","event":"25/10/21 22:45:27 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://2bd63b47b915:46193/files/org.lz4_lz4-java-1.8.0.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.409777","level":"info","event":"25/10/21 22:45:27 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.424784","level":"info","event":"25/10/21 22:45:27 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar at spark://2bd63b47b915:46193/files/org.xerial.snappy_snappy-java-1.1.10.5.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.427321","level":"info","event":"25/10/21 22:45:27 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.xerial.snappy_snappy-java-1.1.10.5.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.469899","level":"info","event":"25/10/21 22:45:27 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://2bd63b47b915:46193/files/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1761086721515","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.472023","level":"info","event":"25/10/21 22:45:27 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/userFiles-dd653d1d-c1fe-48da-92d0-f0985011c759/org.checkerframework_checker-qual-3.42.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.598386","level":"info","event":"25/10/21 22:45:27 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.600776","level":"info","event":"25/10/21 22:45:27 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.600994","level":"info","event":"25/10/21 22:45:27 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.601151","level":"info","event":"25/10/21 22:45:27 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:27.601293","level":"info","event":"25/10/21 22:45:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:29.402919","level":"info","event":"25/10/21 22:45:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:29.656381","level":"info","event":"25/10/21 22:45:29 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.3:7077 after 120 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.009071","level":"info","event":"25/10/21 22:45:30 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.009391","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.009618","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.009809","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.010040","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.010239","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.010433","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.010620","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.010813","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.010978","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.011267","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.011447","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.011627","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.011804","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.011985","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.012200","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.012370","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.012536","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.012701","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.012863","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.013027","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.013200","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.013369","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.013549","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.013819","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.014002","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.014186","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.014368","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.014774","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.017865","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.018732","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.020955","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.021528","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.021871","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.022134","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.022344","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.022539","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.022892","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.023136","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.023390","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.023720","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.023933","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.024322","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.025125","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.025438","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.026088","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.026569","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.026823","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.027201","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.027408","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.027683","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.028142","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.028592","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.028953","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.029689","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.030189","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.030632","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.030843","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.031172","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.031391","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.031571","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.031750","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.031939","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.032158","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.032438","level":"info","event":"at java.base/java.lang.Thread.run(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.032944","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.033072","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.033345","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.033540","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.033728","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.034025","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.034284","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.034603","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.034807","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.035180","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.035414","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.035655","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.035899","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.036010","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.036227","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.036382","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.036563","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.036728","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.036882","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.037023","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.037132","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.037243","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.037451","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.037621","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.037744","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.037863","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.037998","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.038112","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.038198","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.038429","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.038634","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.038761","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:30.038880","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.401758","level":"info","event":"25/10/21 22:45:49 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.474959","level":"info","event":"25/10/21 22:45:49 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.475316","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.475531","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.475748","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.475925","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.476111","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.476277","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.476443","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.476611","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.477117","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.477387","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.477707","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.477994","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.478198","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.478419","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.478613","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.478836","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.479032","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.479215","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.479372","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.479546","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.479723","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.479889","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.480068","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.480315","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.480552","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.480819","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.481025","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.481221","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.481384","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.481631","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.481802","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.481963","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.482133","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.482278","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.482446","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.482594","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.486000","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.486392","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.486636","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.486818","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.486990","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.487393","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.487598","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.487799","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.487964","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.488134","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.488311","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.488466","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.488628","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.489054","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.489342","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.489728","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.489938","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.490098","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.490694","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.491812","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.492370","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.492626","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.492813","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.493278","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.495119","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.495310","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.495518","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.495681","level":"info","event":"at java.base/java.lang.Thread.run(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.495854","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.496001","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.496155","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.496407","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.496582","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.496775","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.496927","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.497085","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.497233","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.497402","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.497662","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.497824","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.497997","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.498222","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.498422","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.498717","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.498888","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.499051","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.499212","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.499438","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.499642","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.499808","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.500034","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.500198","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.500359","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.500510","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.500663","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.500843","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.501010","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.501178","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.501334","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.501544","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:45:49.501727","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.398267","level":"info","event":"25/10/21 22:46:09 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.437401","level":"info","event":"25/10/21 22:46:09 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.437729","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.437912","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.438106","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.438282","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.438451","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.438613","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.438777","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.438891","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.438970","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439048","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439124","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439199","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439274","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439377","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439475","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439600","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439703","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439830","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.439948","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.440081","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.440224","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.440387","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.440542","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.440687","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.440840","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.441008","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.441115","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.441220","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.441314","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.441443","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.441551","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.441653","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.442522","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.442762","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.443022","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.443215","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.443416","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.443589","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.443750","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.443911","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.444029","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.444153","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.444316","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.444558","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.444777","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.445032","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.445207","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.445368","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.445563","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.445815","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.446092","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.446264","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.446407","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.446562","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.446735","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.446901","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.447052","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.447210","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.447381","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.447564","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.447718","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.447925","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.448151","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.448354","level":"info","event":"at java.base/java.lang.Thread.run(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.448495","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.448650","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.448821","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.448986","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.449160","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.449320","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.449450","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.449534","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.449657","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.449803","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.449958","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.450179","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.450313","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.450398","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.450475","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.450571","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.450710","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.450820","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.450904","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.451041","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.451184","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.451328","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.451523","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.451702","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.451864","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.452019","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.452145","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.452275","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.452365","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.452448","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.452578","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.452717","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:09.452865","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.402868","level":"info","event":"25/10/21 22:46:29 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.410840","level":"info","event":"25/10/21 22:46:29 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.434771","level":"info","event":"25/10/21 22:46:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44845.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.436070","level":"info","event":"25/10/21 22:46:29 INFO NettyBlockTransferService: Server created on 2bd63b47b915:44845","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.443688","level":"info","event":"25/10/21 22:46:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.517955","level":"info","event":"25/10/21 22:46:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 2bd63b47b915, 44845, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.539043","level":"info","event":"25/10/21 22:46:29 INFO BlockManagerMasterEndpoint: Registering block manager 2bd63b47b915:44845 with 434.4 MiB RAM, BlockManagerId(driver, 2bd63b47b915, 44845, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.551586","level":"info","event":"25/10/21 22:46:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 2bd63b47b915, 44845, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:29.557053","level":"info","event":"25/10/21 22:46:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 2bd63b47b915, 44845, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:30.159850","level":"info","event":"25/10/21 22:46:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:31.460775","level":"info","event":"25/10/21 22:46:31 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at <unknown>:0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:31.551988","level":"info","event":"25/10/21 22:46:31 INFO SparkUI: Stopped Spark web UI at http://2bd63b47b915:4041","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:31.598803","level":"info","event":"25/10/21 22:46:31 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:31.667672","level":"info","event":"25/10/21 22:46:31 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:31.705138","level":"info","event":"25/10/21 22:46:31 WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:31.794009","level":"info","event":"25/10/21 22:46:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:31.985016","level":"info","event":"25/10/21 22:46:31 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:32.002411","level":"info","event":"25/10/21 22:46:32 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:32.003714","level":"info","event":"25/10/21 22:46:32 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:32.082157","level":"info","event":"25/10/21 22:46:32 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:32.163730","level":"info","event":"25/10/21 22:46:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:32.488245","level":"info","event":"25/10/21 22:46:32 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.462739","level":"info","event":"ERROR:KafkaETL:Error creando SparkSession: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.463271","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.463548","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.463776","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.464039","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.464239","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.464445","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.464644","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.464846","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.465027","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.465206","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.473997","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.475152","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.476422","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.476916","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.477207","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.477433","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.480538","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.481540","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.481933","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.482974","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.483278","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.483505","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.483735","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.483957","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.484171","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.484377","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.484562","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.484750","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.485197","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.492501","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.493103","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.495125","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.496700","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.497228","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.497607","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.498136","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.498578","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.498844","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.499068","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.499287","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.499500","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.499716","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.499884","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.500061","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.500228","level":"info","event":"File \"/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py\", line 279, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.500442","level":"info","event":".getOrCreate()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.500631","level":"info","event":"^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.500816","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 559, in getOrCreate","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.500987","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 641, in __init__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.502339","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py\", line 1627, in __call__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.513873","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py\", line 327, in get_return_value","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.521743","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.522129","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.529075","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.529468","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.529716","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.530004","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.530237","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.530459","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.530682","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.530915","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.531103","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.531316","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.531524","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.531758","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.531969","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.532175","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.532388","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.532574","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.532764","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.532962","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.533157","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.533357","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.533565","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.533769","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.545238","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.545819","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.546166","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.546575","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.546843","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.547118","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.547365","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.557385","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.557733","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.561212","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.561533","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.561770","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.562080","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.562319","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.562524","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.562726","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.562924","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.563118","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.563310","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.563554","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:44.563797","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:45.943945","level":"info","event":"25/10/21 22:46:45 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:45.957404","level":"info","event":"25/10/21 22:46:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-a535655d-5e4f-4775-b762-639f5b13176c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:45.983610","level":"info","event":"25/10/21 22:46:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:46.000210","level":"info","event":"25/10/21 22:46:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba7d7927-ec02-4a46-8fdd-065a345a8dc8/pyspark-ffd72d6e-d407-49ac-9a1c-7e27e3daeb30","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-21T22:46:46.423676","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.7.0,org.postgresql:postgresql:42.7.3 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1215,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-10-21T22:46:46.542898Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-21T22:46:46.545803Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-21T22:46:46.547990Z","level":"info","event":"Task:<Task(SparkSubmitOperator): kafka_test>","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-21T22:46:46.549161Z","level":"info","event":"Failure caused by Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.7.0,org.postgresql:postgresql:42.7.3 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","chan":"stdout","logger":"task"}
