{"timestamp":"2025-11-19T00:40:14.127152","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-11-19T00:40:14.128712","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/KAFKA_AIRFLOW_PYSPARK.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-11-19T00:40:14.357517Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:40:14.359611Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:40:14.360085Z","level":"info","event":"Current task name:kafka_test","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:40:14.360536Z","level":"info","event":"Dag name:kafka_test_api","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:40:14.373400","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-11-19T00:40:14.410684","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-11-19T00:40:14.413572","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=local[*] --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:16.313865","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.164986","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.165358","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.165590","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.165803","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.165981","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.166172","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.166370","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.166593","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.166756","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.166895","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.167075","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.167250","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.167434","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.167574","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.167706","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.167889","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.168035","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.168213","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.168415","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.168555","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.168721","level":"info","event":"primaryResource         file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.168893","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.169083","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.169244","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.169372","level":"info","event":"packages                org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.169477","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.169550","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.169649","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.169781","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.169945","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.170080","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.170227","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.170364","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.170494","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.170632","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.424596","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.629832","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.630219","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.640466","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.640852","level":"info","event":"org.apache.kafka#kafka-clients added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.643085","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-0a29679e-d3d7-476b-9dda-738f89373197;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:21.643316","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:26.958690","level":"info","event":"found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:27.861384","level":"info","event":"found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:28.068506","level":"info","event":"found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:28.262578","level":"info","event":"found org.apache.hadoop#hadoop-client-api;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:28.337598","level":"info","event":"found org.xerial.snappy#snappy-java;1.1.10.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:28.402179","level":"info","event":"found org.slf4j#slf4j-api;2.0.7 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:28.472921","level":"info","event":"found commons-logging#commons-logging;1.1.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:28.560032","level":"info","event":"found com.google.code.findbugs#jsr305;3.0.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:28.724113","level":"info","event":"found org.apache.commons#commons-pool2;2.11.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:29.989573","level":"info","event":"found org.apache.kafka#kafka-clients;3.5.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:30.023593","level":"info","event":"found com.github.luben#zstd-jni;1.5.5-1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:30.054853","level":"info","event":"found org.lz4#lz4-java;1.8.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:30.760396","level":"info","event":"downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:31.047674","level":"info","event":"[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0!spark-sql-kafka-0-10_2.12.jar (963ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:31.171932","level":"info","event":"downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.5.1/kafka-clients-3.5.1.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:32.631317","level":"info","event":"[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.5.1!kafka-clients.jar (1579ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:32.894475","level":"info","event":"downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.0/spark-token-provider-kafka-0-10_2.12-3.5.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:33.043030","level":"info","event":"[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0!spark-token-provider-kafka-0-10_2.12.jar (405ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:33.796480","level":"info","event":"downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.306838","level":"info","event":"[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (1252ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.329990","level":"info","event":":: resolution report :: resolve 8438ms :: artifacts dl 4249ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.330391","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.330616","level":"info","event":"com.github.luben#zstd-jni;1.5.5-1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.331883","level":"info","event":"com.google.code.findbugs#jsr305;3.0.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.332412","level":"info","event":"commons-logging#commons-logging;1.1.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.332737","level":"info","event":"org.apache.commons#commons-pool2;2.11.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.332965","level":"info","event":"org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.333191","level":"info","event":"org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.333390","level":"info","event":"org.apache.kafka#kafka-clients;3.5.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.333549","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.333706","level":"info","event":"org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.333889","level":"info","event":"org.lz4#lz4-java;1.8.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.334059","level":"info","event":"org.slf4j#slf4j-api;2.0.7 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.334234","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.334418","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.334615","level":"info","event":"org.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.5.1] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.334790","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.1 by [org.xerial.snappy#snappy-java;1.1.10.3] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.334977","level":"info","event":"org.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.335222","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.335421","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.335613","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.335823","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.336018","level":"info","event":"|      default     |   15  |   3   |   3   |   3   ||   12  |   4   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.336175","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.360087","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-0a29679e-d3d7-476b-9dda-738f89373197","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.360382","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:34.416121","level":"info","event":"4 artifacts copied, 8 already retrieved (7612kB/58ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:36.213925","level":"info","event":"25/11/19 00:40:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.347603","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.348142","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.352418","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.352889","level":"info","event":"file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.353160","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar,file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar,file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar,file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar,file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar,file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar,file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.362485","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.363252","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.363638","level":"info","event":"(spark.app.submitTime,1763512837234)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.363988","level":"info","event":"(spark.files,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.364257","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.364515","level":"info","event":"(spark.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.364698","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.365085","level":"info","event":"(spark.repl.local.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.365309","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.365485","level":"info","event":"(spark.submit.pyFiles,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.368179","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.368661","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.368912","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.369216","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.369475","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.369891","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.370118","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.370394","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.370612","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.370786","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.371122","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.371318","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.371611","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.376229","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:37.376707","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:42.372870","level":"info","event":"INFO:KafkaETL:=== Iniciando SparkSession ===","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.169909","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.193316","level":"info","event":"25/11/19 00:40:44 INFO SparkContext: Running Spark version 4.0.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.207243","level":"info","event":"25/11/19 00:40:44 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.210260","level":"info","event":"25/11/19 00:40:44 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.355316","level":"info","event":"25/11/19 00:40:44 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.357148","level":"info","event":"25/11/19 00:40:44 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.359018","level":"info","event":"25/11/19 00:40:44 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.363881","level":"info","event":"25/11/19 00:40:44 INFO SparkContext: Submitted application: KafkaETL","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.554787","level":"info","event":"25/11/19 00:40:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.566200","level":"info","event":"25/11/19 00:40:44 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.572975","level":"info","event":"25/11/19 00:40:44 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.973369","level":"info","event":"25/11/19 00:40:44 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.987244","level":"info","event":"25/11/19 00:40:44 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.989210","level":"info","event":"25/11/19 00:40:44 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:44.990950","level":"info","event":"25/11/19 00:40:44 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:45.012485","level":"info","event":"25/11/19 00:40:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:46.426683","level":"info","event":"25/11/19 00:40:46 INFO Utils: Successfully started service 'sparkDriver' on port 44161.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:46.833974","level":"info","event":"25/11/19 00:40:46 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:46.870054","level":"info","event":"25/11/19 00:40:46 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:46.925397","level":"info","event":"25/11/19 00:40:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:46.927113","level":"info","event":"25/11/19 00:40:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:46.940679","level":"info","event":"25/11/19 00:40:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:47.050872","level":"info","event":"25/11/19 00:40:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2e359223-0141-4671-b077-03ea1e5f7a8c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:47.173474","level":"info","event":"25/11/19 00:40:47 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:47.939051","level":"info","event":"25/11/19 00:40:47 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.333080","level":"info","event":"25/11/19 00:40:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.487591","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://2bd63b47b915:44161/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.488445","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar at spark://2bd63b47b915:44161/jars/org.apache.kafka_kafka-clients-3.5.1.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.489382","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://2bd63b47b915:44161/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.490674","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://2bd63b47b915:44161/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.491840","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://2bd63b47b915:44161/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.492649","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://2bd63b47b915:44161/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.493372","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://2bd63b47b915:44161/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.494501","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://2bd63b47b915:44161/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.497370","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://2bd63b47b915:44161/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.499234","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar at spark://2bd63b47b915:44161/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.500405","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar at spark://2bd63b47b915:44161/jars/com.github.luben_zstd-jni-1.5.5-1.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.501326","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://2bd63b47b915:44161/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.515956","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://2bd63b47b915:44161/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.522802","level":"info","event":"25/11/19 00:40:48 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.563095","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar at spark://2bd63b47b915:44161/files/org.apache.kafka_kafka-clients-3.5.1.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.564238","level":"info","event":"25/11/19 00:40:48 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.apache.kafka_kafka-clients-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.586151","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://2bd63b47b915:44161/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.586705","level":"info","event":"25/11/19 00:40:48 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.603391","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://2bd63b47b915:44161/files/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.604038","level":"info","event":"25/11/19 00:40:48 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.678161","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://2bd63b47b915:44161/files/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.679037","level":"info","event":"25/11/19 00:40:48 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.698375","level":"info","event":"25/11/19 00:40:48 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://2bd63b47b915:44161/files/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:48.700297","level":"info","event":"25/11/19 00:40:48 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.047834","level":"info","event":"25/11/19 00:40:49 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://2bd63b47b915:44161/files/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.048295","level":"info","event":"25/11/19 00:40:49 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.168993","level":"info","event":"25/11/19 00:40:49 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://2bd63b47b915:44161/files/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.170207","level":"info","event":"25/11/19 00:40:49 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.xerial.snappy_snappy-java-1.1.10.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.203746","level":"info","event":"25/11/19 00:40:49 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://2bd63b47b915:44161/files/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.204731","level":"info","event":"25/11/19 00:40:49 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.223932","level":"info","event":"25/11/19 00:40:49 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar at spark://2bd63b47b915:44161/files/commons-logging_commons-logging-1.1.3.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.224709","level":"info","event":"25/11/19 00:40:49 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.250784","level":"info","event":"25/11/19 00:40:49 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar at spark://2bd63b47b915:44161/files/com.github.luben_zstd-jni-1.5.5-1.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.251187","level":"info","event":"25/11/19 00:40:49 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/com.github.luben_zstd-jni-1.5.5-1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.331675","level":"info","event":"25/11/19 00:40:49 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://2bd63b47b915:44161/files/org.lz4_lz4-java-1.8.0.jar with timestamp 1763512844120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.336652","level":"info","event":"25/11/19 00:40:49 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/userFiles-51b28cd3-357d-4949-bfd0-95e4bd6d2765/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.522918","level":"info","event":"25/11/19 00:40:49 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.523436","level":"info","event":"25/11/19 00:40:49 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.523669","level":"info","event":"25/11/19 00:40:49 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.523867","level":"info","event":"25/11/19 00:40:49 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:49.524091","level":"info","event":"25/11/19 00:40:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:50.083716","level":"info","event":"25/11/19 00:40:50 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.145853","level":"info","event":"25/11/19 00:40:54 WARN TransportClientFactory: DNS resolution failed for spark-master/<unresolved>:7077 took 4004 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.209392","level":"info","event":"25/11/19 00:40:54 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.209675","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.209768","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.209852","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.209931","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.209993","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210057","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210117","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210177","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210236","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210297","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210358","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210476","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210583","level":"info","event":"Caused by: java.io.IOException: Failed to connect to spark-master/<unresolved>:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210648","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210758","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210854","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:237)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.210968","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:207)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211078","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211190","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211292","level":"info","event":"... 4 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211384","level":"info","event":"Caused by: java.net.UnknownHostException: spark-master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211473","level":"info","event":"at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211567","level":"info","event":"at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211662","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211760","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211889","level":"info","event":"at java.base/java.net.InetAddress.getByName(InetAddress.java:1256)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.211998","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.212112","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.212222","level":"info","event":"at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.212355","level":"info","event":"at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.212459","level":"info","event":"at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.212570","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.212690","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.212809","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.212918","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.213028","level":"info","event":"at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.213180","level":"info","event":"at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.213312","level":"info","event":"at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.213549","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.213821","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:175)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.213979","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.214101","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.214221","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.214349","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.214473","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:625)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.214601","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:105)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.214723","level":"info","event":"at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.214855","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:988)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.214971","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:515)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.215076","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:428)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.215172","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:485)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.215269","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.215392","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.215503","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.215661","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.215775","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.215892","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.216146","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:40:54.216380","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:10.122717","level":"info","event":"25/11/19 00:41:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.880761","level":"info","event":"25/11/19 00:41:13 WARN TransportClientFactory: DNS resolution failed for spark-master/<unresolved>:7077 took 3766 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.897731","level":"info","event":"25/11/19 00:41:13 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.897976","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898122","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898240","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898356","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898448","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898537","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898624","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898721","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898871","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.898974","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899075","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899167","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899251","level":"info","event":"Caused by: java.io.IOException: Failed to connect to spark-master/<unresolved>:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899337","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899446","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899545","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:237)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899643","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:207)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899728","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899813","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899896","level":"info","event":"... 4 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.899982","level":"info","event":"Caused by: java.net.UnknownHostException: spark-master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900096","level":"info","event":"at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900190","level":"info","event":"at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900329","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900429","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900514","level":"info","event":"at java.base/java.net.InetAddress.getByName(InetAddress.java:1256)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900614","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900702","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900810","level":"info","event":"at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900899","level":"info","event":"at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.900988","level":"info","event":"at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901086","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901171","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901259","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901364","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901450","level":"info","event":"at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901550","level":"info","event":"at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901640","level":"info","event":"at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901724","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901807","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:175)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901890","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.901975","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902076","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902193","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902286","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:625)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902371","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:105)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902457","level":"info","event":"at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902541","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:988)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902625","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:515)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902740","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:428)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902892","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:485)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.902994","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.903090","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.903199","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.903286","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.903394","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.903482","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.903645","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:13.903738","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:30.111460","level":"info","event":"25/11/19 00:41:30 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.875459","level":"info","event":"25/11/19 00:41:33 WARN TransportClientFactory: DNS resolution failed for spark-master/<unresolved>:7077 took 3756 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.882127","level":"info","event":"25/11/19 00:41:33 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.882468","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.882656","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.882902","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.883082","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.883229","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.883372","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.883510","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.883650","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.883794","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.883939","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.884080","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.884223","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.884365","level":"info","event":"Caused by: java.io.IOException: Failed to connect to spark-master/<unresolved>:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.884504","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.884642","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.884775","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:237)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.884911","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:207)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.885048","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.885190","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.885333","level":"info","event":"... 4 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.885489","level":"info","event":"Caused by: java.net.UnknownHostException: spark-master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.885626","level":"info","event":"at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.885722","level":"info","event":"at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.885846","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.885938","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886037","level":"info","event":"at java.base/java.net.InetAddress.getByName(InetAddress.java:1256)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886119","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886197","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886275","level":"info","event":"at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886353","level":"info","event":"at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886468","level":"info","event":"at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886571","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886693","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.886901","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.887077","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.887232","level":"info","event":"at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.887322","level":"info","event":"at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.887402","level":"info","event":"at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.887501","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.887588","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:175)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.887747","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.887923","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888042","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888179","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888275","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:625)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888352","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:105)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888454","level":"info","event":"at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888575","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:988)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888720","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:515)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888830","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:428)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.888954","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:485)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.889065","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.889197","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.889329","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.889451","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.889599","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.889734","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.889860","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:33.890050","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.109435","level":"info","event":"25/11/19 00:41:50 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.116553","level":"info","event":"25/11/19 00:41:50 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.139256","level":"info","event":"25/11/19 00:41:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43899.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.140613","level":"info","event":"25/11/19 00:41:50 INFO NettyBlockTransferService: Server created on 2bd63b47b915:43899","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.144578","level":"info","event":"25/11/19 00:41:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.175948","level":"info","event":"25/11/19 00:41:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 2bd63b47b915, 43899, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.199322","level":"info","event":"25/11/19 00:41:50 INFO BlockManagerMasterEndpoint: Registering block manager 2bd63b47b915:43899 with 434.4 MiB RAM, BlockManagerId(driver, 2bd63b47b915, 43899, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.205334","level":"info","event":"25/11/19 00:41:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 2bd63b47b915, 43899, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.207987","level":"info","event":"25/11/19 00:41:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 2bd63b47b915, 43899, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:50.528545","level":"info","event":"25/11/19 00:41:50 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.150566","level":"info","event":"25/11/19 00:41:51 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at <unknown>:0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.195353","level":"info","event":"25/11/19 00:41:51 INFO SparkUI: Stopped Spark web UI at http://2bd63b47b915:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.227011","level":"info","event":"25/11/19 00:41:51 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.263088","level":"info","event":"25/11/19 00:41:51 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.311481","level":"info","event":"25/11/19 00:41:51 WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.385974","level":"info","event":"25/11/19 00:41:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.454880","level":"info","event":"25/11/19 00:41:51 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.457100","level":"info","event":"25/11/19 00:41:51 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.458002","level":"info","event":"25/11/19 00:41:51 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.489351","level":"info","event":"25/11/19 00:41:51 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.496312","level":"info","event":"25/11/19 00:41:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:51.546514","level":"info","event":"25/11/19 00:41:51 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.151667","level":"info","event":"ERROR:KafkaETL:Error creando SparkSession: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.152031","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.152293","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.152537","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.152704","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.152882","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.153052","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.153216","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.153378","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.153539","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.153700","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.153861","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.154039","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.154241","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.154429","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.154605","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.158025","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.161441","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.161806","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.162031","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.162244","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.162473","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.162767","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.162958","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.163089","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.163267","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.163427","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.163604","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.163797","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.163979","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.164139","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.164345","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.164596","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.164794","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.164963","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.165140","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.165304","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.165466","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.165658","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.165794","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.165886","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.165971","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.166055","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.166140","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.166270","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.166398","level":"info","event":"File \"/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py\", line 18, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.166519","level":"info","event":"spark = SparkSession.builder.appName(\"KafkaETL\").getOrCreate()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.166671","level":"info","event":"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.166870","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 559, in getOrCreate","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.169019","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 641, in __init__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.172587","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py\", line 1627, in __call__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.178058","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py\", line 327, in get_return_value","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.181254","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:59.123876Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:41:59.125403Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:41:59.126200Z","level":"info","event":"Task:<Task(SparkSubmitOperator): kafka_test>","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:41:59.126915Z","level":"info","event":"Failure caused by Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=local[*] --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:41:56.181592","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.181838","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.182105","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.182371","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.182716","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.182922","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.183112","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.183293","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.183471","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.183648","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.183827","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.184011","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.184189","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.184594","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.184829","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.185078","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.185277","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.185467","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.185653","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.185837","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.186019","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.186206","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.186478","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.186655","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.186815","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.187141","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.188042","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.189429","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.190559","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.190968","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.191583","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.192468","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.193513","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.193777","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.193982","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.194169","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.194351","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.194526","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.194691","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.194845","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.195010","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.195191","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.195366","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.195542","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.613450","level":"info","event":"25/11/19 00:41:56 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.614623","level":"info","event":"25/11/19 00:41:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.642401","level":"info","event":"25/11/19 00:41:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-96bd2c3a-d547-4031-953d-95c6dd70cae3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.674309","level":"info","event":"25/11/19 00:41:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-77a1f6e5-b73e-4704-add3-39b6e80047b4/pyspark-d970bddf-ee93-491a-b6a2-8f2a5d095de0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:41:56.930174","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=local[*] --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1215,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
