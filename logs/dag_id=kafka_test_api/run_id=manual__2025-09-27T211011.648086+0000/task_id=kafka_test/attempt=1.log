{"timestamp":"2025-09-27T21:10:15.290567","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-27T21:10:15.294181","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/KAFKA_AIRFLOW_PYSPARK.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-27T21:10:15.499512Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-27T21:10:15.501842Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-27T21:10:15.502866Z","level":"info","event":"Current task name:kafka_test","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-27T21:10:15.504147Z","level":"info","event":"Dag name:kafka_test_api","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-27T21:10:15.511681","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-09-27T21:10:15.591523","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-09-27T21:10:15.596589","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0,org.apache.kafka:kafka-clients:3.7.0 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:17.254613","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.691960","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.692195","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.692310","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.692402","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.692508","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.692701","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.692809","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.692894","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.692975","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693053","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693133","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693213","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693291","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693367","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693447","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693537","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693693","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693816","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693892","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.693967","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.694117","level":"info","event":"primaryResource         file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.694201","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.694278","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.694355","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.694430","level":"info","event":"packages                org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0,org.apache.kafka:kafka-clients:3.7.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.694725","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.694931","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.695128","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.695299","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.695392","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.695549","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.695640","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.695720","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.695899","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.695992","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:20.970217","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:21.227097","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:21.227442","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:21.238799","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:21.239314","level":"info","event":"org.apache.kafka#kafka-clients added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:21.240985","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-a4ae930d-165c-4643-8a29-48c499039ebe;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:21.241217","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:21.755337","level":"info","event":"found org.apache.spark#spark-sql-kafka-0-10_2.13;4.0.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.035044","level":"info","event":"found org.apache.spark#spark-token-provider-kafka-0-10_2.13;4.0.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.104113","level":"info","event":"found org.apache.kafka#kafka-clients;3.9.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.191109","level":"info","event":"found org.lz4#lz4-java;1.8.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.231409","level":"info","event":"found org.xerial.snappy#snappy-java;1.1.10.7 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.273493","level":"info","event":"found org.slf4j#slf4j-api;2.0.16 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.331837","level":"info","event":"found org.apache.hadoop#hadoop-client-runtime;3.4.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.395234","level":"info","event":"found org.apache.hadoop#hadoop-client-api;3.4.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.462394","level":"info","event":"found com.google.code.findbugs#jsr305;3.0.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.510830","level":"info","event":"found org.scala-lang.modules#scala-parallel-collections_2.13;1.2.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.550153","level":"info","event":"found org.apache.commons#commons-pool2;2.12.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.602241","level":"info","event":":: resolution report :: resolve 1332ms :: artifacts dl 29ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.602493","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.603910","level":"info","event":"com.google.code.findbugs#jsr305;3.0.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.604210","level":"info","event":"org.apache.commons#commons-pool2;2.12.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.604396","level":"info","event":"org.apache.hadoop#hadoop-client-api;3.4.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.604556","level":"info","event":"org.apache.hadoop#hadoop-client-runtime;3.4.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.604760","level":"info","event":"org.apache.kafka#kafka-clients;3.9.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.604914","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.13;4.0.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.605071","level":"info","event":"org.apache.spark#spark-token-provider-kafka-0-10_2.13;4.0.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.605301","level":"info","event":"org.lz4#lz4-java;1.8.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.605483","level":"info","event":"org.scala-lang.modules#scala-parallel-collections_2.13;1.2.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.605695","level":"info","event":"org.slf4j#slf4j-api;2.0.16 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.605880","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.7 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.606054","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.606255","level":"info","event":"org.apache.kafka#kafka-clients;3.7.0 by [org.apache.kafka#kafka-clients;3.9.0] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.606413","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.606564","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.606708","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.606860","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.607155","level":"info","event":"|      default     |   12  |   0   |   0   |   1   ||   11  |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.607420","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.623173","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-a4ae930d-165c-4643-8a29-48c499039ebe","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.623544","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:22.638739","level":"info","event":"0 artifacts copied, 11 already retrieved (0kB/16ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.279505","level":"info","event":"25/09/27 21:10:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.648314","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.648685","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.651627","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.651853","level":"info","event":"file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.651965","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-4.0.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-4.0.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.2.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.9.0.jar,file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.12.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.4.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.7.jar,file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.16.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.4.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.654859","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655180","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655312","level":"info","event":"(spark.app.submitTime,1759007423614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655405","level":"info","event":"(spark.files,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655488","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655569","level":"info","event":"(spark.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655655","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655792","level":"info","event":"(spark.repl.local.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655880","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.655957","level":"info","event":"(spark.submit.pyFiles,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.657118","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.657422","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-4.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.657654","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-4.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.657825","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.2.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.657981","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.9.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.658176","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.658423","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.12.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.658614","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.4.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.658872","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.659158","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.659389","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.16.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.659581","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.4.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.659702","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:23.659803","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:27.380111","level":"info","event":"INFO:KafkaETL:=== Iniciando SparkSession ===","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.562551","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.572690","level":"info","event":"25/09/27 21:10:29 INFO SparkContext: Running Spark version 4.0.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.576940","level":"info","event":"25/09/27 21:10:29 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.578967","level":"info","event":"25/09/27 21:10:29 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.624768","level":"info","event":"25/09/27 21:10:29 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.625354","level":"info","event":"25/09/27 21:10:29 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.626742","level":"info","event":"25/09/27 21:10:29 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.631194","level":"info","event":"25/09/27 21:10:29 INFO SparkContext: Submitted application: KafkaETL","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.687254","level":"info","event":"25/09/27 21:10:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.694596","level":"info","event":"25/09/27 21:10:29 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.697311","level":"info","event":"25/09/27 21:10:29 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.857019","level":"info","event":"25/09/27 21:10:29 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.860003","level":"info","event":"25/09/27 21:10:29 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.860944","level":"info","event":"25/09/27 21:10:29 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.861959","level":"info","event":"25/09/27 21:10:29 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:29.867927","level":"info","event":"25/09/27 21:10:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:30.352461","level":"info","event":"25/09/27 21:10:30 INFO Utils: Successfully started service 'sparkDriver' on port 37249.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:30.455665","level":"info","event":"25/09/27 21:10:30 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:30.487716","level":"info","event":"25/09/27 21:10:30 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:30.521264","level":"info","event":"25/09/27 21:10:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:30.522302","level":"info","event":"25/09/27 21:10:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:30.532520","level":"info","event":"25/09/27 21:10:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:30.622265","level":"info","event":"25/09/27 21:10:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dfd46694-18e5-4cde-8acf-40cef9fa6cf6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:30.682858","level":"info","event":"25/09/27 21:10:30 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.077834","level":"info","event":"25/09/27 21:10:31 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.261339","level":"info","event":"25/09/27 21:10:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.378096","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-4.0.0.jar at spark://b4f9970ea699:37249/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-4.0.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.379497","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-4.0.0.jar at spark://b4f9970ea699:37249/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-4.0.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.380678","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.2.0.jar at spark://b4f9970ea699:37249/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.2.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.382320","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.9.0.jar at spark://b4f9970ea699:37249/jars/org.apache.kafka_kafka-clients-3.9.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.383234","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://b4f9970ea699:37249/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.384093","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.12.0.jar at spark://b4f9970ea699:37249/jars/org.apache.commons_commons-pool2-2.12.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.385310","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.4.1.jar at spark://b4f9970ea699:37249/jars/org.apache.hadoop_hadoop-client-runtime-3.4.1.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.386137","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://b4f9970ea699:37249/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.387417","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.7.jar at spark://b4f9970ea699:37249/jars/org.xerial.snappy_snappy-java-1.1.10.7.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.388388","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.16.jar at spark://b4f9970ea699:37249/jars/org.slf4j_slf4j-api-2.0.16.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.389352","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.4.1.jar at spark://b4f9970ea699:37249/jars/org.apache.hadoop_hadoop-client-api-3.4.1.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.399793","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-4.0.0.jar at spark://b4f9970ea699:37249/files/org.apache.spark_spark-sql-kafka-0-10_2.13-4.0.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.405668","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-4.0.0.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.apache.spark_spark-sql-kafka-0-10_2.13-4.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.442836","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-4.0.0.jar at spark://b4f9970ea699:37249/files/org.apache.spark_spark-token-provider-kafka-0-10_2.13-4.0.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.443671","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-4.0.0.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.apache.spark_spark-token-provider-kafka-0-10_2.13-4.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.458370","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.2.0.jar at spark://b4f9970ea699:37249/files/org.scala-lang.modules_scala-parallel-collections_2.13-1.2.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.459298","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.2.0.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.scala-lang.modules_scala-parallel-collections_2.13-1.2.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.476721","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.9.0.jar at spark://b4f9970ea699:37249/files/org.apache.kafka_kafka-clients-3.9.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.477088","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.9.0.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.apache.kafka_kafka-clients-3.9.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.530359","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://b4f9970ea699:37249/files/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.531218","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.547538","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.12.0.jar at spark://b4f9970ea699:37249/files/org.apache.commons_commons-pool2-2.12.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.548393","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.12.0.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.apache.commons_commons-pool2-2.12.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.559888","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.4.1.jar at spark://b4f9970ea699:37249/files/org.apache.hadoop_hadoop-client-runtime-3.4.1.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.560126","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.4.1.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.apache.hadoop_hadoop-client-runtime-3.4.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.868589","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://b4f9970ea699:37249/files/org.lz4_lz4-java-1.8.0.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.869059","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.883983","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.7.jar at spark://b4f9970ea699:37249/files/org.xerial.snappy_snappy-java-1.1.10.7.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.884337","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.7.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.xerial.snappy_snappy-java-1.1.10.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.908478","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.16.jar at spark://b4f9970ea699:37249/files/org.slf4j_slf4j-api-2.0.16.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.909078","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.16.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.slf4j_slf4j-api-2.0.16.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.918740","level":"info","event":"25/09/27 21:10:31 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.4.1.jar at spark://b4f9970ea699:37249/files/org.apache.hadoop_hadoop-client-api-3.4.1.jar with timestamp 1759007429550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:31.920063","level":"info","event":"25/09/27 21:10:31 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.4.1.jar to /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/userFiles-2481f581-7cc7-45c4-af8b-14a46cf46290/org.apache.hadoop_hadoop-client-api-3.4.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.369752","level":"info","event":"25/09/27 21:10:32 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.370107","level":"info","event":"25/09/27 21:10:32 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.370318","level":"info","event":"25/09/27 21:10:32 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.370877","level":"info","event":"25/09/27 21:10:32 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.371583","level":"info","event":"25/09/27 21:10:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.724850","level":"info","event":"25/09/27 21:10:32 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.889608","level":"info","event":"25/09/27 21:10:32 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.5:7077 after 100 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.976298","level":"info","event":"25/09/27 21:10:32 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.976552","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.976685","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.976765","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.976837","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.976904","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.976972","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977037","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977102","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977166","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977230","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977292","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977356","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977419","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977486","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:597)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977549","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977614","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977676","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2224)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977738","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977802","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977868","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.977980","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978102","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978177","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978285","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978362","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978427","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978492","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978556","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978621","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978686","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978749","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978812","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978875","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.978939","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979002","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979168","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979271","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979341","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979406","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979471","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979535","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979644","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979725","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979791","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979855","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.979935","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.980073","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.980206","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.980324","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.980455","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.980592","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.981034","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.981391","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.981814","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.982077","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.982242","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.982393","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.982536","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.982669","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.983009","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.983203","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.983334","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.983460","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.983591","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.983849","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.983970","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.984240","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.984333","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.984507","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.984594","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.984668","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.984808","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.984955","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.985038","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.985110","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.985209","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.985436","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.985577","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.985713","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.985849","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.985965","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986043","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986286","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986381","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986455","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986548","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986623","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986736","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986844","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986921","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.986992","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.987170","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.987284","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.987357","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.987430","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.987639","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:32.987817","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.724894","level":"info","event":"25/09/27 21:10:52 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.742457","level":"info","event":"25/09/27 21:10:52 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.743010","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.743306","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.743716","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.744038","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.744281","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.744510","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.745046","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.745776","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.746335","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.746596","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.746816","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.747033","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.747245","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.747756","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:597)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.748221","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.748730","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.749049","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2224)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.749747","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.750384","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.750766","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.751103","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.751600","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.752169","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.753058","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.753502","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.753928","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.754208","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.754467","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.754702","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.754927","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.755248","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.755517","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.755735","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.755945","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.756374","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.756888","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.757176","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.757576","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.757983","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.758218","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.758433","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.758750","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.759205","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.759665","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.760098","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.760594","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.761081","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.761534","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.761803","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.762062","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.762452","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.762845","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.763399","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.763666","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.763889","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.764103","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.764880","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.765583","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.766071","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.766329","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.766549","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.766770","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.766978","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.767221","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.767642","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.768096","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.768807","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.769269","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.769696","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.770154","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.770437","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.770659","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.771751","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.772890","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.773396","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.773881","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.774386","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.774902","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.775402","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.775941","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.776432","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.777037","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.777477","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.777945","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.778587","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.779713","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.781548","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.782621","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.783020","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.783494","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.783886","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.784356","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.785010","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.785320","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.785731","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.786199","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:10:52.786858","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.723325","level":"info","event":"25/09/27 21:11:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.744466","level":"info","event":"25/09/27 21:11:12 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.744744","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.744840","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.744924","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.744996","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745066","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745134","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745221","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745329","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745400","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745465","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745531","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745596","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745662","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745732","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:597)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745824","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.745956","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746045","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2224)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746113","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746180","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746245","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746311","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746383","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746488","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746558","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746624","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746688","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746752","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746832","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746929","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.746996","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747061","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747126","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747191","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747255","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747322","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747388","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747462","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747576","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747650","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747717","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747783","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747848","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747915","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.747982","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748047","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748112","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748176","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748240","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748305","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748370","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748436","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748501","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748690","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748791","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748857","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748923","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.748988","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749054","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749119","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749184","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749264","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749324","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749386","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749448","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749511","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749572","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749645","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749712","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749774","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749837","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749899","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.749961","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.750194","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.750352","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.750486","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.750562","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.750627","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.750760","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.750878","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.750950","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751109","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751187","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751253","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751317","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751380","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751484","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751595","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751829","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.751989","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.752313","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.752492","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.752703","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.752852","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.753036","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.753148","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.753220","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:12.753287","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:32.724290","level":"info","event":"25/09/27 21:11:32 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:32.726234","level":"info","event":"25/09/27 21:11:32 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:32.972653","level":"info","event":"25/09/27 21:11:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46557.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:32.973651","level":"info","event":"25/09/27 21:11:32 INFO NettyBlockTransferService: Server created on b4f9970ea699:46557","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:32.995324","level":"info","event":"25/09/27 21:11:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:33.105845","level":"info","event":"25/09/27 21:11:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b4f9970ea699, 46557, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:33.136701","level":"info","event":"25/09/27 21:11:33 INFO BlockManagerMasterEndpoint: Registering block manager b4f9970ea699:46557 with 434.4 MiB RAM, BlockManagerId(driver, b4f9970ea699, 46557, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:33.144528","level":"info","event":"25/09/27 21:11:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b4f9970ea699, 46557, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:33.148363","level":"info","event":"25/09/27 21:11:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b4f9970ea699, 46557, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:33.542765","level":"info","event":"25/09/27 21:11:33 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.139762","level":"info","event":"25/09/27 21:11:34 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at <unknown>:0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.160488","level":"info","event":"25/09/27 21:11:34 INFO SparkUI: Stopped Spark web UI at http://b4f9970ea699:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.166560","level":"info","event":"25/09/27 21:11:34 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.176919","level":"info","event":"25/09/27 21:11:34 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.188132","level":"info","event":"25/09/27 21:11:34 WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.207213","level":"info","event":"25/09/27 21:11:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.253063","level":"info","event":"25/09/27 21:11:34 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.255674","level":"info","event":"25/09/27 21:11:34 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.258410","level":"info","event":"25/09/27 21:11:34 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.279357","level":"info","event":"25/09/27 21:11:34 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.284420","level":"info","event":"25/09/27 21:11:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:34.330268","level":"info","event":"25/09/27 21:11:34 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.097831","level":"info","event":"ERROR:KafkaETL:Error creando SparkSession: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.098169","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.098358","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.098517","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.098744","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.098841","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.098927","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099009","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099100","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099180","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099258","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099336","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099413","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099489","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099564","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099642","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099770","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099868","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.099951","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100033","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100111","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100189","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100267","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100343","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100421","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100499","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100578","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100655","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100732","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100809","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100884","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.100961","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101062","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101142","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101219","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101296","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101372","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101448","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101525","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101601","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101676","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101750","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101849","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.101975","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.102060","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.102142","level":"info","event":"File \"/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py\", line 12, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.108607","level":"info","event":"spark = SparkSession.builder.appName(\"KafkaETL\").getOrCreate()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.109072","level":"info","event":"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.109291","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 559, in getOrCreate","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.110019","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 641, in __init__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.110997","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py\", line 1627, in __call__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.112037","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py\", line 327, in get_return_value","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.113942","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.114233","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.114429","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.114696","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.114907","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115101","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115210","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115297","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115381","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115462","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115541","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115618","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115695","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115771","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115864","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.115999","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116142","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116234","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116316","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116398","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116482","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116607","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116740","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116852","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.116931","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.117010","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.117141","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.117370","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.117484","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.117732","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.118029","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.118158","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.118348","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.118445","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.118747","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.118922","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.119072","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.119218","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.119470","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.119723","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.119939","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.120098","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.120385","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.120552","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.124424","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.544286","level":"info","event":"25/09/27 21:11:39 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.546920","level":"info","event":"25/09/27 21:11:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.560853","level":"info","event":"25/09/27 21:11:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-b84a6953-592d-4dc4-9c9d-e86c907a7015/pyspark-17528e33-9285-4e9f-ba98-2d8d879dd49d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.573679","level":"info","event":"25/09/27 21:11:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-c6d4e0a4-79f3-4357-8fab-98b0f98d723d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-27T21:11:39.691603","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0,org.apache.kafka:kafka-clients:3.7.0 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1215,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-09-27T21:11:39.696984Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-27T21:11:39.697964Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-27T21:11:39.698736Z","level":"info","event":"Task:<Task(SparkSubmitOperator): kafka_test>","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-27T21:11:39.699434Z","level":"info","event":"Failure caused by Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0,org.apache.kafka:kafka-clients:3.7.0 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","chan":"stdout","logger":"task"}
