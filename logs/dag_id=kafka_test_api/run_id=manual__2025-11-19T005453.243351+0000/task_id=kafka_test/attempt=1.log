{"timestamp":"2025-11-19T00:54:56.059647","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-11-19T00:54:56.064495","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/KAFKA_AIRFLOW_PYSPARK.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-11-19T00:54:56.253743Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:54:56.256672Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:54:56.257340Z","level":"info","event":"Current task name:kafka_test","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:54:56.258010Z","level":"info","event":"Dag name:kafka_test_api","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:54:56.261147","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-11-19T00:54:56.311192","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-11-19T00:54:56.317455","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=local[*] --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:54:57.721027","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.265222","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.265687","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.265986","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.266311","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.266578","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.266811","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.267271","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.267502","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.267717","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.267944","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.268162","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.269059","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.269326","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.269585","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.269857","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.270076","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.270278","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.270604","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.270822","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.271026","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.271238","level":"info","event":"primaryResource         file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.271436","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.271618","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.271794","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.271987","level":"info","event":"packages                org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.272174","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.272357","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.272541","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.272738","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.272928","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.273129","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.273314","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.273495","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.273870","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.274059","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.587695","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.801263","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.801861","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.812606","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.813062","level":"info","event":"org.apache.kafka#kafka-clients added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.815132","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-c05f4d9e-6aa1-44ec-83b4-3ecfd9958a2b;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:02.815465","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:03.349876","level":"info","event":"found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:03.537065","level":"info","event":"found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:03.667489","level":"info","event":"found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:03.804403","level":"info","event":"found org.apache.hadoop#hadoop-client-api;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:03.947853","level":"info","event":"found org.xerial.snappy#snappy-java;1.1.10.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.003802","level":"info","event":"found org.slf4j#slf4j-api;2.0.7 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.063096","level":"info","event":"found commons-logging#commons-logging;1.1.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.122974","level":"info","event":"found com.google.code.findbugs#jsr305;3.0.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.159546","level":"info","event":"found org.apache.commons#commons-pool2;2.11.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.192042","level":"info","event":"found org.apache.kafka#kafka-clients;3.5.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.223797","level":"info","event":"found com.github.luben#zstd-jni;1.5.5-1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.254594","level":"info","event":"found org.lz4#lz4-java;1.8.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.341864","level":"info","event":":: resolution report :: resolve 1470ms :: artifacts dl 56ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.342884","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.344518","level":"info","event":"com.github.luben#zstd-jni;1.5.5-1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.344936","level":"info","event":"com.google.code.findbugs#jsr305;3.0.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.345108","level":"info","event":"commons-logging#commons-logging;1.1.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.345283","level":"info","event":"org.apache.commons#commons-pool2;2.11.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.345471","level":"info","event":"org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.345718","level":"info","event":"org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.345936","level":"info","event":"org.apache.kafka#kafka-clients;3.5.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.346141","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.346393","level":"info","event":"org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.346567","level":"info","event":"org.lz4#lz4-java;1.8.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.346761","level":"info","event":"org.slf4j#slf4j-api;2.0.7 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.346959","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.347177","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.347402","level":"info","event":"org.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.5.1] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.347620","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.1 by [org.xerial.snappy#snappy-java;1.1.10.3] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.347860","level":"info","event":"org.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.348065","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.348258","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.348450","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.348641","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.348835","level":"info","event":"|      default     |   15  |   0   |   0   |   3   ||   12  |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.349011","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.366274","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-c05f4d9e-6aa1-44ec-83b4-3ecfd9958a2b","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.366558","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.395564","level":"info","event":"0 artifacts copied, 12 already retrieved (0kB/30ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:04.842388","level":"info","event":"25/11/19 00:55:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.179028","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.179371","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.180646","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.180853","level":"info","event":"file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.181038","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar,file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar,file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar,file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar,file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar,file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar,file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.184843","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.185173","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.185382","level":"info","event":"(spark.app.submitTime,1763513705133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.185750","level":"info","event":"(spark.files,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.185897","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.186014","level":"info","event":"(spark.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.186114","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.186291","level":"info","event":"(spark.repl.local.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.186557","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.186810","level":"info","event":"(spark.submit.pyFiles,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.187093","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.187458","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.187756","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.187969","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.188235","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.188517","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.188674","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.188774","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.188891","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.189071","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.189252","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.189488","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.189745","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.189966","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:05.190134","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:08.809010","level":"info","event":"INFO:KafkaETL:=== Iniciando SparkSession ===","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.742980","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.753677","level":"info","event":"25/11/19 00:55:10 INFO SparkContext: Running Spark version 4.0.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.758845","level":"info","event":"25/11/19 00:55:10 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.760839","level":"info","event":"25/11/19 00:55:10 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.809231","level":"info","event":"25/11/19 00:55:10 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.810042","level":"info","event":"25/11/19 00:55:10 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.810888","level":"info","event":"25/11/19 00:55:10 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.812828","level":"info","event":"25/11/19 00:55:10 INFO SparkContext: Submitted application: KafkaETL","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.862383","level":"info","event":"25/11/19 00:55:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.868062","level":"info","event":"25/11/19 00:55:10 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.869939","level":"info","event":"25/11/19 00:55:10 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.947332","level":"info","event":"25/11/19 00:55:10 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.948808","level":"info","event":"25/11/19 00:55:10 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.949887","level":"info","event":"25/11/19 00:55:10 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.950961","level":"info","event":"25/11/19 00:55:10 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:10.954513","level":"info","event":"25/11/19 00:55:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.278729","level":"info","event":"25/11/19 00:55:11 INFO Utils: Successfully started service 'sparkDriver' on port 36179.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.324837","level":"info","event":"25/11/19 00:55:11 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.342072","level":"info","event":"25/11/19 00:55:11 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.362144","level":"info","event":"25/11/19 00:55:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.363188","level":"info","event":"25/11/19 00:55:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.367946","level":"info","event":"25/11/19 00:55:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.400470","level":"info","event":"25/11/19 00:55:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ac908935-c58e-4025-86d2-2afb432abde7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.437744","level":"info","event":"25/11/19 00:55:11 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.701288","level":"info","event":"25/11/19 00:55:11 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:11.889851","level":"info","event":"25/11/19 00:55:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.016519","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://2bd63b47b915:36179/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.017953","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar at spark://2bd63b47b915:36179/jars/org.apache.kafka_kafka-clients-3.5.1.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.018763","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://2bd63b47b915:36179/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.020001","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://2bd63b47b915:36179/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.021278","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://2bd63b47b915:36179/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.022490","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://2bd63b47b915:36179/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.024252","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://2bd63b47b915:36179/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.025409","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://2bd63b47b915:36179/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.027005","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://2bd63b47b915:36179/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.028510","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar at spark://2bd63b47b915:36179/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.029738","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar at spark://2bd63b47b915:36179/jars/com.github.luben_zstd-jni-1.5.5-1.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.030702","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://2bd63b47b915:36179/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.038788","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://2bd63b47b915:36179/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.044025","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.067001","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar at spark://2bd63b47b915:36179/files/org.apache.kafka_kafka-clients-3.5.1.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.067882","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.5.1.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.apache.kafka_kafka-clients-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.091467","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://2bd63b47b915:36179/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.092392","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.103771","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://2bd63b47b915:36179/files/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.104429","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.115634","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://2bd63b47b915:36179/files/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.116297","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.129654","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://2bd63b47b915:36179/files/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.130409","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.269694","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://2bd63b47b915:36179/files/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.270379","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.551327","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://2bd63b47b915:36179/files/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.552102","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.xerial.snappy_snappy-java-1.1.10.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.570052","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://2bd63b47b915:36179/files/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.570953","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.581728","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar at spark://2bd63b47b915:36179/files/commons-logging_commons-logging-1.1.3.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.582042","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.594788","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar at spark://2bd63b47b915:36179/files/com.github.luben_zstd-jni-1.5.5-1.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.595166","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-1.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/com.github.luben_zstd-jni-1.5.5-1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.641964","level":"info","event":"25/11/19 00:55:12 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://2bd63b47b915:36179/files/org.lz4_lz4-java-1.8.0.jar with timestamp 1763513710727","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.642555","level":"info","event":"25/11/19 00:55:12 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/userFiles-94668a63-ce5b-49d3-b751-5e008a80926d/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.692775","level":"info","event":"25/11/19 00:55:12 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.693235","level":"info","event":"25/11/19 00:55:12 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.693651","level":"info","event":"25/11/19 00:55:12 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.694272","level":"info","event":"25/11/19 00:55:12 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:12.694785","level":"info","event":"25/11/19 00:55:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:13.095904","level":"info","event":"25/11/19 00:55:13 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.008212","level":"info","event":"25/11/19 00:55:17 WARN TransportClientFactory: DNS resolution failed for spark-master/<unresolved>:7077 took 3881 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046112","level":"info","event":"25/11/19 00:55:17 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046340","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046430","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046494","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046553","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046609","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046665","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046719","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046775","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046829","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046894","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.046957","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047011","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047126","level":"info","event":"Caused by: java.io.IOException: Failed to connect to spark-master/<unresolved>:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047190","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047246","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047301","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:237)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047354","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:207)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047407","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047461","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047516","level":"info","event":"... 4 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047571","level":"info","event":"Caused by: java.net.UnknownHostException: spark-master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047624","level":"info","event":"at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047677","level":"info","event":"at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047730","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047783","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047836","level":"info","event":"at java.base/java.net.InetAddress.getByName(InetAddress.java:1256)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047895","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.047976","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048096","level":"info","event":"at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048204","level":"info","event":"at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048267","level":"info","event":"at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048322","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048376","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048430","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048484","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048537","level":"info","event":"at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048604","level":"info","event":"at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048661","level":"info","event":"at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048725","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048780","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:175)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048833","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048887","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048941","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.048994","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049089","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:625)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049148","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:105)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049214","level":"info","event":"at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049271","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:988)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049335","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:515)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049391","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:428)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049444","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:485)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049499","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049555","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049609","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049662","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049768","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049843","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049901","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:17.049957","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:33.094849","level":"info","event":"25/11/19 00:55:33 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.874900","level":"info","event":"25/11/19 00:55:36 WARN TransportClientFactory: DNS resolution failed for spark-master/<unresolved>:7077 took 3777 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878263","level":"info","event":"25/11/19 00:55:36 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878417","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878489","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878550","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878607","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878662","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878716","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878787","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878899","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.878958","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879012","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879127","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879190","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879243","level":"info","event":"Caused by: java.io.IOException: Failed to connect to spark-master/<unresolved>:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879304","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879389","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879446","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:237)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879497","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:207)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879548","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879599","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879651","level":"info","event":"... 4 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879703","level":"info","event":"Caused by: java.net.UnknownHostException: spark-master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879755","level":"info","event":"at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879806","level":"info","event":"at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879858","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879909","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.879960","level":"info","event":"at java.base/java.net.InetAddress.getByName(InetAddress.java:1256)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880010","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880063","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880126","level":"info","event":"at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880174","level":"info","event":"at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880222","level":"info","event":"at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880269","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880316","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880364","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880412","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880460","level":"info","event":"at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880508","level":"info","event":"at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880556","level":"info","event":"at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880604","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880651","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:175)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880698","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880745","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880793","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880840","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880887","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:625)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880935","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:105)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.880984","level":"info","event":"at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881032","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:988)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881080","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:515)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881141","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:428)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881187","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:485)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881239","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881286","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881333","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881380","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881426","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881473","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881520","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:36.881566","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:53.093558","level":"info","event":"25/11/19 00:55:53 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.923415","level":"info","event":"25/11/19 00:55:56 WARN TransportClientFactory: DNS resolution failed for spark-master/<unresolved>:7077 took 3827 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.927861","level":"info","event":"25/11/19 00:55:56 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928078","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928181","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928268","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928368","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928450","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928528","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928603","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928677","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928751","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928825","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.928933","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929048","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929127","level":"info","event":"Caused by: java.io.IOException: Failed to connect to spark-master/<unresolved>:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929270","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929368","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929455","level":"info","event":"at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:237)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929558","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:207)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929642","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929715","level":"info","event":"at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929790","level":"info","event":"... 4 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929866","level":"info","event":"Caused by: java.net.UnknownHostException: spark-master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.929956","level":"info","event":"at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930037","level":"info","event":"at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930133","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930211","level":"info","event":"at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930285","level":"info","event":"at java.base/java.net.InetAddress.getByName(InetAddress.java:1256)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930357","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930430","level":"info","event":"at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930503","level":"info","event":"at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930578","level":"info","event":"at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930651","level":"info","event":"at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930734","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.930883","level":"info","event":"at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931026","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931116","level":"info","event":"at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931193","level":"info","event":"at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931268","level":"info","event":"at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931342","level":"info","event":"at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931417","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931489","level":"info","event":"at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:175)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931563","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931637","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931710","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931789","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.931909","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:625)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932002","level":"info","event":"at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:105)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932079","level":"info","event":"at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932153","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:988)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932227","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:515)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932301","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:428)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932375","level":"info","event":"at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:485)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932460","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932538","level":"info","event":"at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932612","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932687","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932759","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932832","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.932906","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:55:56.933002","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.092999","level":"info","event":"25/11/19 00:56:13 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.094442","level":"info","event":"25/11/19 00:56:13 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.109644","level":"info","event":"25/11/19 00:56:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45781.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.110887","level":"info","event":"25/11/19 00:56:13 INFO NettyBlockTransferService: Server created on 2bd63b47b915:45781","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.114252","level":"info","event":"25/11/19 00:56:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.136003","level":"info","event":"25/11/19 00:56:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 2bd63b47b915, 45781, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.149115","level":"info","event":"25/11/19 00:56:13 INFO BlockManagerMasterEndpoint: Registering block manager 2bd63b47b915:45781 with 434.4 MiB RAM, BlockManagerId(driver, 2bd63b47b915, 45781, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.153359","level":"info","event":"25/11/19 00:56:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 2bd63b47b915, 45781, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.155880","level":"info","event":"25/11/19 00:56:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 2bd63b47b915, 45781, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:13.425045","level":"info","event":"25/11/19 00:56:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.032922","level":"info","event":"25/11/19 00:56:14 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at <unknown>:0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.057889","level":"info","event":"25/11/19 00:56:14 INFO SparkUI: Stopped Spark web UI at http://2bd63b47b915:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.070316","level":"info","event":"25/11/19 00:56:14 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.080592","level":"info","event":"25/11/19 00:56:14 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.092847","level":"info","event":"25/11/19 00:56:14 WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.118977","level":"info","event":"25/11/19 00:56:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.155162","level":"info","event":"25/11/19 00:56:14 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.156844","level":"info","event":"25/11/19 00:56:14 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.157750","level":"info","event":"25/11/19 00:56:14 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.172283","level":"info","event":"25/11/19 00:56:14 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.177703","level":"info","event":"25/11/19 00:56:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:14.225849","level":"info","event":"25/11/19 00:56:14 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.983381","level":"info","event":"ERROR:KafkaETL:Error creando SparkSession: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.983785","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.984077","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.984316","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.984549","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.984729","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.984931","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.985063","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.985168","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.985273","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.985372","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.985467","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.985645","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.985844","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.986024","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.986234","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.986426","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.986645","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.986891","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.987905","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.988223","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.988369","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.988529","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.988732","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.988954","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.989181","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.989356","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.989508","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.989671","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.989857","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.990067","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.990242","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.990452","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.990791","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.991250","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.991612","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.991898","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.992189","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.992430","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.992634","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.993081","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.993796","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.995194","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.995556","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.996001","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:20.996595","level":"info","event":"File \"/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py\", line 18, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.000920","level":"info","event":"spark = SparkSession.builder.appName(\"KafkaETL\").getOrCreate()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.001499","level":"info","event":"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.001913","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 559, in getOrCreate","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.005012","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 641, in __init__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.008024","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py\", line 1627, in __call__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.011166","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py\", line 327, in get_return_value","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.015192","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.015536","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.015760","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.015956","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.016159","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.016377","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.016593","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.016790","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.017006","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.017186","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.017489","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.017701","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.018209","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.018555","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.018792","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.019110","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.019344","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.019562","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.019786","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.020041","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.020325","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.020500","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.020694","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.020846","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.020990","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.021139","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.021282","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.021460","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.021603","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.021745","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.021890","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.022029","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.022184","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.022379","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.022567","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.022781","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.023105","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.023399","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.023628","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.023864","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.024057","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.024260","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.024550","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.024765","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.024996","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.415506","level":"info","event":"25/11/19 00:56:21 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.418131","level":"info","event":"25/11/19 00:56:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-60c02b9d-962f-46ed-9a79-58cfdfa5fdbc","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.438511","level":"info","event":"25/11/19 00:56:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.453009","level":"info","event":"25/11/19 00:56:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-0fdbd55f-de7a-4db8-b48f-59686d9e0cd7/pyspark-af42cfb6-2bf9-4a0f-a7d7-973bd1f0b18c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-11-19T00:56:21.582581","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=local[*] --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1215,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-11-19T00:56:21.686270Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:56:21.687307Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:56:21.688203Z","level":"info","event":"Task:<Task(SparkSubmitOperator): kafka_test>","chan":"stdout","logger":"task"}
{"timestamp":"2025-11-19T00:56:21.690404Z","level":"info","event":"Failure caused by Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=local[*] --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","chan":"stdout","logger":"task"}
