{"timestamp":"2025-10-22T00:01:33.140129","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-10-22T00:01:33.141675","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/KAFKA_AIRFLOW_PYSPARK.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-10-22T00:01:33.221668Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-22T00:01:33.222731Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-22T00:01:33.225766Z","level":"info","event":"Current task name:kafka_test","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-22T00:01:33.226336Z","level":"info","event":"Dag name:kafka_test_api","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-22T00:01:33.225900","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-10-22T00:01:33.242494","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-10-22T00:01:33.245677","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.7.0,org.postgresql:postgresql:42.7.3 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:33.792830","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.356848","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.357107","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.357269","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.357411","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.357667","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.357813","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.357943","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.358076","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.358215","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.358352","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.358478","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.358604","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.358722","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.358836","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.358956","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.359089","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.359209","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.359334","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.359473","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.359612","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.359738","level":"info","event":"primaryResource         file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.359844","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.359971","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360105","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360238","level":"info","event":"packages                org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.7.0,org.postgresql:postgresql:42.7.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360353","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360427","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360495","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360560","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360636","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360701","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360779","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360844","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360908","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.360970","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.531916","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.687194","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.687566","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.694750","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.695019","level":"info","event":"org.apache.kafka#kafka-clients added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.695168","level":"info","event":"org.postgresql#postgresql added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.696907","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-a76df96b-7db2-46f6-8022-c3a7f4a596e2;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.697144","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.911667","level":"info","event":"found org.apache.spark#spark-sql-kafka-0-10_2.13;3.5.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:37.986494","level":"info","event":"found org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.5.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.033087","level":"info","event":"found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.081699","level":"info","event":"found org.apache.hadoop#hadoop-client-api;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.112699","level":"info","event":"found org.xerial.snappy#snappy-java;1.1.10.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.140665","level":"info","event":"found org.slf4j#slf4j-api;2.0.7 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.179934","level":"info","event":"found commons-logging#commons-logging;1.1.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.240154","level":"info","event":"found com.google.code.findbugs#jsr305;3.0.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.286285","level":"info","event":"found org.scala-lang.modules#scala-parallel-collections_2.13;1.0.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.325440","level":"info","event":"found org.apache.commons#commons-pool2;2.11.1 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.353029","level":"info","event":"found org.apache.kafka#kafka-clients;3.7.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.388117","level":"info","event":"found com.github.luben#zstd-jni;1.5.5-6 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.406156","level":"info","event":"found org.lz4#lz4-java;1.8.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.423500","level":"info","event":"found org.xerial.snappy#snappy-java;1.1.10.5 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.446209","level":"info","event":"found org.postgresql#postgresql;42.7.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.468837","level":"info","event":"found org.checkerframework#checker-qual;3.42.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.554954","level":"info","event":":: resolution report :: resolve 799ms :: artifacts dl 59ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.555362","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.555861","level":"info","event":"com.github.luben#zstd-jni;1.5.5-6 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.556216","level":"info","event":"com.google.code.findbugs#jsr305;3.0.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.556475","level":"info","event":"commons-logging#commons-logging;1.1.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.556727","level":"info","event":"org.apache.commons#commons-pool2;2.11.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.557697","level":"info","event":"org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.558057","level":"info","event":"org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.558293","level":"info","event":"org.apache.kafka#kafka-clients;3.7.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.558729","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.13;3.5.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.559001","level":"info","event":"org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.5.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.559193","level":"info","event":"org.checkerframework#checker-qual;3.42.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.559341","level":"info","event":"org.lz4#lz4-java;1.8.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.559501","level":"info","event":"org.postgresql#postgresql;42.7.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.559666","level":"info","event":"org.scala-lang.modules#scala-parallel-collections_2.13;1.0.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.559868","level":"info","event":"org.slf4j#slf4j-api;2.0.7 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.560028","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.5 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.560176","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.560342","level":"info","event":"org.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.7.0] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.560494","level":"info","event":"org.xerial.snappy#snappy-java;1.1.10.3 by [org.xerial.snappy#snappy-java;1.1.10.5] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.560654","level":"info","event":"org.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.560792","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.560950","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.561084","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.561219","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.561357","level":"info","event":"|      default     |   18  |   0   |   0   |   3   ||   15  |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.561646","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.578895","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-a76df96b-7db2-46f6-8022-c3a7f4a596e2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.579345","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.600111","level":"info","event":"0 artifacts copied, 15 already retrieved (0kB/21ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:38.994067","level":"info","event":"25/10/22 00:01:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.278336","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.278681","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.281674","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.281984","level":"info","event":"file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.282238","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar,file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar,file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar,file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar,file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar,file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar,file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar,file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar,file:///home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.285436","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.285896","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.286627","level":"info","event":"(spark.app.submitTime,1761091299235)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.286966","level":"info","event":"(spark.files,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.287493","level":"info","event":"(spark.hadoop.hadoop.user.name,airflow)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.287951","level":"info","event":"(spark.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.288183","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.288458","level":"info","event":"(spark.repl.local.jars,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.288804","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.289110","level":"info","event":"(spark.submit.pyFiles,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.289614","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.290141","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.290393","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.290656","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.291943","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.292253","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.292464","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.292625","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.292780","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.292989","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.293148","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.293289","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.293430","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.293746","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.293909","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.294047","level":"info","event":"file:///home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.294184","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:39.294321","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:41.868333","level":"info","event":"INFO:KafkaETL:=== Iniciando SparkSession ===","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:43.853372","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:43.874891","level":"info","event":"25/10/22 00:01:43 INFO SparkContext: Running Spark version 4.0.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:43.881441","level":"info","event":"25/10/22 00:01:43 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:43.885896","level":"info","event":"25/10/22 00:01:43 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.031316","level":"info","event":"25/10/22 00:01:44 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.032344","level":"info","event":"25/10/22 00:01:44 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.033729","level":"info","event":"25/10/22 00:01:44 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.034219","level":"info","event":"25/10/22 00:01:44 INFO SparkContext: Submitted application: KafkaETL","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.151985","level":"info","event":"25/10/22 00:01:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.182275","level":"info","event":"25/10/22 00:01:44 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.186819","level":"info","event":"25/10/22 00:01:44 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.344260","level":"info","event":"25/10/22 00:01:44 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.347363","level":"info","event":"25/10/22 00:01:44 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.349190","level":"info","event":"25/10/22 00:01:44 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.350890","level":"info","event":"25/10/22 00:01:44 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.356336","level":"info","event":"25/10/22 00:01:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:44.997900","level":"info","event":"25/10/22 00:01:44 INFO Utils: Successfully started service 'sparkDriver' on port 35871.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.050745","level":"info","event":"25/10/22 00:01:45 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.076128","level":"info","event":"25/10/22 00:01:45 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.104298","level":"info","event":"25/10/22 00:01:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.105928","level":"info","event":"25/10/22 00:01:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.113564","level":"info","event":"25/10/22 00:01:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.155261","level":"info","event":"25/10/22 00:01:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-70d585f3-19e0-4999-9106-21d4d0c03aea","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.246218","level":"info","event":"25/10/22 00:01:45 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.479675","level":"info","event":"25/10/22 00:01:45 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.603949","level":"info","event":"25/10/22 00:01:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.697051","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar at spark://2bd63b47b915:35871/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.699494","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar at spark://2bd63b47b915:35871/jars/org.apache.kafka_kafka-clients-3.7.0.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.700647","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar at spark://2bd63b47b915:35871/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.701918","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar at spark://2bd63b47b915:35871/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.703193","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar at spark://2bd63b47b915:35871/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.704562","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://2bd63b47b915:35871/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.705569","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://2bd63b47b915:35871/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.706395","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://2bd63b47b915:35871/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.707173","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://2bd63b47b915:35871/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.707935","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://2bd63b47b915:35871/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.708935","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar at spark://2bd63b47b915:35871/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.710440","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar at spark://2bd63b47b915:35871/jars/com.github.luben_zstd-jni-1.5.5-6.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.711670","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://2bd63b47b915:35871/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.713329","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar at spark://2bd63b47b915:35871/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.714357","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added JAR file:///home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://2bd63b47b915:35871/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.722601","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar at spark://2bd63b47b915:35871/files/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.726831","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.apache.spark_spark-sql-kafka-0-10_2.13-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.751631","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar at spark://2bd63b47b915:35871/files/org.apache.kafka_kafka-clients-3.7.0.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.752080","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.kafka_kafka-clients-3.7.0.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.apache.kafka_kafka-clients-3.7.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.797561","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar at spark://2bd63b47b915:35871/files/org.postgresql_postgresql-42.7.3.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.798703","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.postgresql_postgresql-42.7.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.819382","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar at spark://2bd63b47b915:35871/files/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.820389","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.5.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.831547","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar at spark://2bd63b47b915:35871/files/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.832294","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.850887","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://2bd63b47b915:35871/files/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.851552","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.862774","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://2bd63b47b915:35871/files/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.863361","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.875468","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://2bd63b47b915:35871/files/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.876144","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.919879","level":"info","event":"25/10/22 00:01:45 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://2bd63b47b915:35871/files/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:45.920131","level":"info","event":"25/10/22 00:01:45 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.005105","level":"info","event":"25/10/22 00:01:46 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://2bd63b47b915:35871/files/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.005855","level":"info","event":"25/10/22 00:01:46 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.014894","level":"info","event":"25/10/22 00:01:46 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar at spark://2bd63b47b915:35871/files/commons-logging_commons-logging-1.1.3.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.015155","level":"info","event":"25/10/22 00:01:46 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.028494","level":"info","event":"25/10/22 00:01:46 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar at spark://2bd63b47b915:35871/files/com.github.luben_zstd-jni-1.5.5-6.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.028920","level":"info","event":"25/10/22 00:01:46 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/com.github.luben_zstd-jni-1.5.5-6.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/com.github.luben_zstd-jni-1.5.5-6.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.047396","level":"info","event":"25/10/22 00:01:46 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar at spark://2bd63b47b915:35871/files/org.lz4_lz4-java-1.8.0.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.047903","level":"info","event":"25/10/22 00:01:46 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.061064","level":"info","event":"25/10/22 00:01:46 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar at spark://2bd63b47b915:35871/files/org.xerial.snappy_snappy-java-1.1.10.5.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.061359","level":"info","event":"25/10/22 00:01:46 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.xerial.snappy_snappy-java-1.1.10.5.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.074508","level":"info","event":"25/10/22 00:01:46 INFO SparkContext: Added file file:///home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://2bd63b47b915:35871/files/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1761091303812","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.075373","level":"info","event":"25/10/22 00:01:46 INFO Utils: Copying /home/airflow/.ivy2.5.2/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/userFiles-19c50bfe-a2c1-45fd-b236-c72a717e8a15/org.checkerframework_checker-qual-3.42.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.127647","level":"info","event":"25/10/22 00:01:46 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.127982","level":"info","event":"25/10/22 00:01:46 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.129847","level":"info","event":"25/10/22 00:01:46 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.130225","level":"info","event":"25/10/22 00:01:46 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.130476","level":"info","event":"25/10/22 00:01:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.504223","level":"info","event":"25/10/22 00:01:46 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.566157","level":"info","event":"25/10/22 00:01:46 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.3:7077 after 32 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.661155","level":"info","event":"25/10/22 00:01:46 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.661462","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.661587","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.661723","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.661832","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.661920","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662005","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662086","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662166","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662247","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662326","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662408","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662487","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662567","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662649","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662727","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662804","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662880","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.662956","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663032","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663108","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663184","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663260","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663350","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663426","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663501","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663588","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663743","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663832","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663907","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.663981","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.664137","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.664228","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.664306","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.664381","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.664455","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.664527","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.664698","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.664860","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.665003","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.665128","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.665210","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.665413","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.665499","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.665587","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.665730","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.665885","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666039","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666137","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666214","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666288","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666362","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666435","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666507","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666580","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666654","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666729","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666804","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666878","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.666966","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.667055","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.667131","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.667203","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.667290","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.667436","level":"info","event":"at java.base/java.lang.Thread.run(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.667575","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.667760","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.667926","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.668022","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.668140","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.668327","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.668481","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.668622","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.668747","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.668889","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.668992","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.669070","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.669149","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.669330","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.669441","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.669522","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.669610","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.669708","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.669855","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.670044","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.670136","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.670215","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.670360","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.670517","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.670678","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.670883","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.671046","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.671143","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.671253","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.671411","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.671567","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.671681","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:01:46.671757","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.506254","level":"info","event":"25/10/22 00:02:06 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.589939","level":"info","event":"25/10/22 00:02:06 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.590499","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.590828","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.591160","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.591363","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.591569","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.591764","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.591923","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.592083","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.592234","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.592396","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.592590","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.592745","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.592910","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.593436","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.593630","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.593812","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.593972","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.594143","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.594295","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.594451","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.594631","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.594810","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.595015","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.595204","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.595375","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.595539","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.595698","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.595873","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.596007","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.596145","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.596280","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.596425","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.596581","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.596726","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.596865","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.597030","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.597207","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.597520","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.597801","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.597951","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.598086","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.598246","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.598377","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.598500","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.598620","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.598748","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.598875","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.599010","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.599175","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.599313","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.599679","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.599947","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600096","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600241","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600380","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600475","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600557","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600634","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600715","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600817","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.600930","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.601009","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.601093","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.601686","level":"info","event":"at java.base/java.lang.Thread.run(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.602048","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.602237","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.602406","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.602568","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.603303","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.603670","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.603848","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.604247","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.604504","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.604625","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.604715","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.604796","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.604879","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.605005","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.605189","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.605558","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.605936","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.606156","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.606266","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.606351","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.606432","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.606527","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.606676","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.606922","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.607121","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.607298","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.607488","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.607628","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.607777","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.607941","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.608226","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.608463","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:06.608621","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.502888","level":"info","event":"25/10/22 00:02:26 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.551979","level":"info","event":"25/10/22 00:02:26 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.552440","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.552707","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.552888","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.553195","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.553440","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.553607","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.553744","level":"info","event":"at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.553876","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.554001","level":"info","event":"at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.554281","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.554559","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.554788","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.554935","level":"info","event":"Caused by: java.lang.RuntimeException: java.io.InvalidClassException: org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence; local class incompatible: stream classdesc serialVersionUID = 5378738997755484868, local class serialVersionUID = 7789290765573734431","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.555173","level":"info","event":"at java.base/java.io.ObjectStreamClass.initNonProxy(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.555440","level":"info","event":"at java.base/java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.555767","level":"info","event":"at java.base/java.io.ObjectInputStream.readClassDesc(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.556016","level":"info","event":"at java.base/java.io.ObjectInputStream.readOrdinaryObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.556228","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject0(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.556448","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.556674","level":"info","event":"at java.base/java.io.ObjectInputStream.readObject(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.556876","level":"info","event":"at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.557082","level":"info","event":"at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.557290","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$2(NettyRpcEnv.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.557496","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.557697","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:352)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.557906","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$deserialize$1(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.558141","level":"info","event":"at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.558442","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:298)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.558702","level":"info","event":"at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:646)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.558956","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:697)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.559194","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:682)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.559456","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.559689","level":"info","event":"at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.559914","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.560268","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.561734","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.563192","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.563393","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.563511","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.563625","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.563836","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.563951","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.564053","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.564169","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.564376","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.564523","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.564626","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.564725","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.564918","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.565037","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.565134","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.565230","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.565395","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.565536","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.565637","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.565736","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.565833","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.566064","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.566185","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.566470","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.566605","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.566707","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.566804","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567057","level":"info","event":"at java.base/java.lang.Thread.run(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567182","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567285","level":"info","event":"at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567383","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567479","level":"info","event":"at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567673","level":"info","event":"at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567789","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567886","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.567985","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.568082","level":"info","event":"at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.568261","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.568368","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.568467","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.568562","level":"info","event":"at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.568659","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.568777","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.568906","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569008","level":"info","event":"at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569105","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569317","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569413","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569495","level":"info","event":"at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569574","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569682","level":"info","event":"at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569841","level":"info","event":"at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.569938","level":"info","event":"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.570024","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.570104","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.570182","level":"info","event":"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.570420","level":"info","event":"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.570517","level":"info","event":"at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.570598","level":"info","event":"at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.570678","level":"info","event":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:26.570762","level":"info","event":"... 1 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.503499","level":"info","event":"25/10/22 00:02:46 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.505747","level":"info","event":"25/10/22 00:02:46 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.525317","level":"info","event":"25/10/22 00:02:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34429.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.526943","level":"info","event":"25/10/22 00:02:46 INFO NettyBlockTransferService: Server created on 2bd63b47b915:34429","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.531619","level":"info","event":"25/10/22 00:02:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.565678","level":"info","event":"25/10/22 00:02:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 2bd63b47b915, 34429, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.580610","level":"info","event":"25/10/22 00:02:46 INFO BlockManagerMasterEndpoint: Registering block manager 2bd63b47b915:34429 with 434.4 MiB RAM, BlockManagerId(driver, 2bd63b47b915, 34429, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.585815","level":"info","event":"25/10/22 00:02:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 2bd63b47b915, 34429, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.589137","level":"info","event":"25/10/22 00:02:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 2bd63b47b915, 34429, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:46.952447","level":"info","event":"25/10/22 00:02:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.732679","level":"info","event":"25/10/22 00:02:47 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at <unknown>:0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.796416","level":"info","event":"25/10/22 00:02:47 INFO SparkUI: Stopped Spark web UI at http://2bd63b47b915:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.813319","level":"info","event":"25/10/22 00:02:47 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.825374","level":"info","event":"25/10/22 00:02:47 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.841401","level":"info","event":"25/10/22 00:02:47 WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.873433","level":"info","event":"25/10/22 00:02:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.917013","level":"info","event":"25/10/22 00:02:47 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.942443","level":"info","event":"25/10/22 00:02:47 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.944139","level":"info","event":"25/10/22 00:02:47 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:47.995396","level":"info","event":"25/10/22 00:02:47 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:48.006351","level":"info","event":"25/10/22 00:02:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:48.133039","level":"info","event":"25/10/22 00:02:48 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.010314","level":"info","event":"ERROR:KafkaETL:Error creando SparkSession: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.010715","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.010973","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.011184","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.011354","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.011523","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.011685","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.011855","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.012014","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.012184","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.012363","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.012509","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.012662","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.012812","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.012983","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.013136","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.013296","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.013438","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.013585","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.013780","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.013938","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.014117","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.014277","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.015504","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.016715","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.018921","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.019274","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.019461","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.019745","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.020446","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.021143","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.021635","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.022144","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.022590","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.022989","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.023313","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.023506","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.023711","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.023882","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.024078","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.024238","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.024419","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.024580","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.024758","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.024991","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.025172","level":"info","event":"File \"/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py\", line 19, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.055818","level":"info","event":"spark = SparkSession.builder.appName(\"KafkaETL\").getOrCreate()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.056202","level":"info","event":"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.056428","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 559, in getOrCreate","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.062156","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 641, in __init__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.066600","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py\", line 1627, in __call__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.068746","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py\", line 327, in get_return_value","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.072370","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.sql.classic.SparkSession.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.072775","level":"info","event":": java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.073004","level":"info","event":"This stopped SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.073230","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.073402","level":"info","event":"org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.073576","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.073730","level":"info","event":"java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.073877","level":"info","event":"java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.074024","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.074163","level":"info","event":"java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.074302","level":"info","event":"py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.074487","level":"info","event":"py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.074642","level":"info","event":"py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.074950","level":"info","event":"py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.075149","level":"info","event":"py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.075344","level":"info","event":"py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.075504","level":"info","event":"py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.075687","level":"info","event":"java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.075870","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.076061","level":"info","event":"And it was stopped at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.076221","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.076581","level":"info","event":"org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.076786","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.076998","level":"info","event":"The currently active SparkContext was created at:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.077165","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.077488","level":"info","event":"(No active SparkContext.)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.081834","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.082372","level":"info","event":"at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.083440","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.085112","level":"info","event":"at org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.085717","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.086044","level":"info","event":"at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.086310","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.086579","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.086750","level":"info","event":"at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.087135","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.087392","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.087603","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.087819","level":"info","event":"at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.087991","level":"info","event":"at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.088191","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.088355","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.088509","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.088695","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.088870","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.561159","level":"info","event":"25/10/22 00:02:54 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.564258","level":"info","event":"25/10/22 00:02:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92/pyspark-7aed0aea-3e77-48da-bb16-512269821b50","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.575689","level":"info","event":"25/10/22 00:02:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-6325589c-2632-4d72-9d3b-b2ebf0de3602","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.586655","level":"info","event":"25/10/22 00:02:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-eaf43e3a-8907-4f10-8173-e056c905fc92","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-10-22T00:02:54.707316","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.7.0,org.postgresql:postgresql:42.7.3 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1215,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-10-22T00:02:54.712445Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-22T00:02:54.713811Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-22T00:02:54.715396Z","level":"info","event":"Task:<Task(SparkSubmitOperator): kafka_test>","chan":"stdout","logger":"task"}
{"timestamp":"2025-10-22T00:02:54.716431Z","level":"info","event":"Failure caused by Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.hadoop.hadoop.user.name=airflow --packages org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.7.0,org.postgresql:postgresql:42.7.3 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_4.py. Error code is: 1.","chan":"stdout","logger":"task"}
