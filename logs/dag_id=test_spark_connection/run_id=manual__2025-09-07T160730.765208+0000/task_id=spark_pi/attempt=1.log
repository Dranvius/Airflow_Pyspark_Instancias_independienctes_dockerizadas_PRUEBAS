{"timestamp":"2025-09-07T16:07:39.340941","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-07T16:07:39.342290","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/spark_wordcount_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-07T16:07:40.104143Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-07T16:07:40.105465Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-07T16:07:40.106105Z","level":"info","event":"Current task name:spark_pi","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-07T16:07:40.106686Z","level":"info","event":"Dag name:test_spark_connection","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-07T16:07:40.117696","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-09-07T16:07:40.158883","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-09-07T16:07:40.163127","level":"info","event":"Spark-Submit cmd: spark-submit --master spark-master:7077 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name arrow-spark --deploy-mode cluster /opt/airflow/pyspark_instancia_pruebas/test_2.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:42.247153","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.277532","level":"info","event":"Exception in thread \"main\" org.apache.spark.SparkException: Cluster deploy mode is currently not supported for python applications on standalone clusters.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.278181","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.error(SparkSubmit.scala:1045)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.278302","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:301)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.278419","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.278548","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.278638","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.278737","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.278884","level":"info","event":"at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.279029","level":"info","event":"at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.279181","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-07T16:07:46.329324","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master spark-master:7077 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name arrow-spark --deploy-mode cluster /opt/airflow/pyspark_instancia_pruebas/test_2.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1215,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-09-07T16:07:48.348536Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-07T16:07:48.349032Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-07T16:07:48.349411Z","level":"info","event":"Task:<Task(SparkSubmitOperator): spark_pi>","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-07T16:07:48.349841Z","level":"info","event":"Failure caused by Cannot execute: spark-submit --master spark-master:7077 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name arrow-spark --deploy-mode cluster /opt/airflow/pyspark_instancia_pruebas/test_2.py. Error code is: 1.","chan":"stdout","logger":"task"}
