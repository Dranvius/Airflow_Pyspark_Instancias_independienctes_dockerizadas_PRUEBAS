{"timestamp":"2025-09-23T17:46:39.652194","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-23T17:46:39.653157","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/EJERCICIO_2.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-23T17:46:39.750435Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:46:39.752003Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:46:39.752614Z","level":"info","event":"Current task name:broadcast_salting","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:46:39.753144Z","level":"info","event":"Dag name:spark_join_con_mucha_informacion","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:46:39.753358","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-09-23T17:46:39.775335","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-09-23T17:46:39.778548","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.executor.memory=1g --conf spark.driver.memory=512m --conf spark.executor.cores=1 --conf spark.executor.instances=2 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_2.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:40.583272","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.139057","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.139473","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.139733","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.140030","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.140341","level":"info","event":"executorMemory          1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.140563","level":"info","event":"executorCores           1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.140742","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.140900","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.141072","level":"info","event":"driverMemory            512m","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.141349","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.141533","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.141708","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.141881","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.142049","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.142233","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.142400","level":"info","event":"numExecutors            2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.142573","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.142727","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.143041","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.143247","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.143409","level":"info","event":"primaryResource         file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_2.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.143582","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.143949","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.144196","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.144408","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.144591","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.144837","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.145052","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.145284","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.145544","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.145758","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.145944","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.146218","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.146422","level":"info","event":"(spark.executor.instances,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.146583","level":"info","event":"(spark.executor.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.146753","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.147059","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.147334","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.776622","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.777074","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.779047","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.779438","level":"info","event":"file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_2.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.779695","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.783064","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.783591","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.783883","level":"info","event":"(spark.app.submitTime,1758649603685)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.784122","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.784440","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.784717","level":"info","event":"(spark.executor.instances,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.784955","level":"info","event":"(spark.executor.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.785224","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.785461","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.785672","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.785893","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.786089","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.786894","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:43.787245","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.077179","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.099145","level":"info","event":"25/09/23 17:46:47 INFO SparkContext: Running Spark version 4.0.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.111336","level":"info","event":"25/09/23 17:46:47 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.113521","level":"info","event":"25/09/23 17:46:47 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.296058","level":"info","event":"25/09/23 17:46:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.415781","level":"info","event":"25/09/23 17:46:47 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.417317","level":"info","event":"25/09/23 17:46:47 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.419205","level":"info","event":"25/09/23 17:46:47 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.422127","level":"info","event":"25/09/23 17:46:47 INFO SparkContext: Submitted application: SkewCartesianExample","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.496254","level":"info","event":"25/09/23 17:46:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.515099","level":"info","event":"25/09/23 17:46:47 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.521845","level":"info","event":"25/09/23 17:46:47 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.649548","level":"info","event":"25/09/23 17:46:47 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.652180","level":"info","event":"25/09/23 17:46:47 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.654001","level":"info","event":"25/09/23 17:46:47 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.655893","level":"info","event":"25/09/23 17:46:47 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:47.663459","level":"info","event":"25/09/23 17:46:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:48.237453","level":"info","event":"25/09/23 17:46:48 INFO Utils: Successfully started service 'sparkDriver' on port 39833.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:48.364789","level":"info","event":"25/09/23 17:46:48 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:48.423005","level":"info","event":"25/09/23 17:46:48 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:48.483211","level":"info","event":"25/09/23 17:46:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:48.484637","level":"info","event":"25/09/23 17:46:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:48.499454","level":"info","event":"25/09/23 17:46:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:48.585234","level":"info","event":"25/09/23 17:46:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b8a20198-f132-4a98-8ec0-31746389978c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:48.665893","level":"info","event":"25/09/23 17:46:48 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.001883","level":"info","event":"25/09/23 17:46:49 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.184371","level":"info","event":"25/09/23 17:46:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.281369","level":"info","event":"25/09/23 17:46:49 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.281652","level":"info","event":"25/09/23 17:46:49 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.282207","level":"info","event":"25/09/23 17:46:49 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.282795","level":"info","event":"25/09/23 17:46:49 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.283799","level":"info","event":"25/09/23 17:46:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.506145","level":"info","event":"25/09/23 17:46:49 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.577437","level":"info","event":"25/09/23 17:46:49 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.10:7077 after 31 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.781177","level":"info","event":"25/09/23 17:46:49 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250923174649-0000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.799868","level":"info","event":"25/09/23 17:46:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42119.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.800270","level":"info","event":"25/09/23 17:46:49 INFO NettyBlockTransferService: Server created on 619c5b104b4c:42119","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.803802","level":"info","event":"25/09/23 17:46:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.830624","level":"info","event":"25/09/23 17:46:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 619c5b104b4c, 42119, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.843120","level":"info","event":"25/09/23 17:46:49 INFO BlockManagerMasterEndpoint: Registering block manager 619c5b104b4c:42119 with 127.2 MiB RAM, BlockManagerId(driver, 619c5b104b4c, 42119, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.847965","level":"info","event":"25/09/23 17:46:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 619c5b104b4c, 42119, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.850943","level":"info","event":"25/09/23 17:46:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 619c5b104b4c, 42119, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.909888","level":"info","event":"25/09/23 17:46:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923174649-0000/0 on worker-20250923174535-172.19.0.12-40131 (172.19.0.12:40131) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.911583","level":"info","event":"25/09/23 17:46:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923174649-0000/0 on hostPort 172.19.0.12:40131 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.912809","level":"info","event":"25/09/23 17:46:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923174649-0000/1 on worker-20250923174535-172.19.0.12-40131 (172.19.0.12:40131) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.917579","level":"info","event":"25/09/23 17:46:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923174649-0000/1 on hostPort 172.19.0.12:40131 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.918044","level":"info","event":"25/09/23 17:46:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923174649-0000/2 on worker-20250923174535-172.19.0.12-40131 (172.19.0.12:40131) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.918366","level":"info","event":"25/09/23 17:46:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923174649-0000/2 on hostPort 172.19.0.12:40131 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.918592","level":"info","event":"25/09/23 17:46:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923174649-0000/3 on worker-20250923174535-172.19.0.12-40131 (172.19.0.12:40131) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.918787","level":"info","event":"25/09/23 17:46:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923174649-0000/3 on hostPort 172.19.0.12:40131 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.918970","level":"info","event":"25/09/23 17:46:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923174649-0000/4 on worker-20250923174535-172.19.0.12-40131 (172.19.0.12:40131) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.920402","level":"info","event":"25/09/23 17:46:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923174649-0000/4 on hostPort 172.19.0.12:40131 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.929699","level":"info","event":"25/09/23 17:46:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923174649-0000/5 on worker-20250923174535-172.19.0.12-40131 (172.19.0.12:40131) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:49.930682","level":"info","event":"25/09/23 17:46:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923174649-0000/5 on hostPort 172.19.0.12:40131 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:51.072330","level":"info","event":"25/09/23 17:46:51 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:51.185451","level":"info","event":"25/09/23 17:46:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923174649-0000/5 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:51.185912","level":"info","event":"25/09/23 17:46:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923174649-0000/2 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:51.195809","level":"info","event":"25/09/23 17:46:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923174649-0000/4 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:51.199631","level":"info","event":"25/09/23 17:46:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923174649-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:51.203930","level":"info","event":"25/09/23 17:46:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923174649-0000/3 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:46:51.209242","level":"info","event":"25/09/23 17:46:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923174649-0000/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:07.063211","level":"info","event":"25/09/23 17:47:07 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:07.096745","level":"info","event":"25/09/23 17:47:07 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:16.662485","level":"info","event":"Tiempo creación de datos: 10.79 segundos","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:23.796398","level":"info","event":"25/09/23 17:47:23 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:60182) with ID 3, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:23.890657","level":"info","event":"25/09/23 17:47:23 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:60192) with ID 1, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:24.783429","level":"info","event":"25/09/23 17:47:24 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:60218) with ID 5, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:25.191406","level":"info","event":"25/09/23 17:47:25 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:60202) with ID 0, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:26.782502","level":"info","event":"25/09/23 17:47:26 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:60236) with ID 4, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:26.799787","level":"info","event":"25/09/23 17:47:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:35049 with 434.4 MiB RAM, BlockManagerId(5, 172.19.0.12, 35049, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:26.893821","level":"info","event":"25/09/23 17:47:26 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:59490) with ID 2, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:26.988068","level":"info","event":"25/09/23 17:47:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:39099 with 434.4 MiB RAM, BlockManagerId(3, 172.19.0.12, 39099, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:27.329881","level":"info","event":"25/09/23 17:47:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:34171 with 434.4 MiB RAM, BlockManagerId(0, 172.19.0.12, 34171, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:27.585015","level":"info","event":"25/09/23 17:47:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:34899 with 434.4 MiB RAM, BlockManagerId(1, 172.19.0.12, 34899, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:27.722442","level":"info","event":"25/09/23 17:47:27 INFO CodeGenerator: Code generated in 1420.806563 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.383832","level":"info","event":"25/09/23 17:47:28 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.438223","level":"info","event":"25/09/23 17:47:28 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:39561 with 434.4 MiB RAM, BlockManagerId(2, 172.19.0.12, 39561, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.449546","level":"info","event":"25/09/23 17:47:28 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:40127 with 434.4 MiB RAM, BlockManagerId(4, 172.19.0.12, 40127, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.555212","level":"info","event":"25/09/23 17:47:28 INFO DAGScheduler: Got job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.574712","level":"info","event":"25/09/23 17:47:28 INFO DAGScheduler: Final stage: ResultStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.601216","level":"info","event":"25/09/23 17:47:28 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.622554","level":"info","event":"25/09/23 17:47:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.702342","level":"info","event":"25/09/23 17:47:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:28.952005","level":"info","event":"25/09/23 17:47:28 INFO MemoryStore: MemoryStore started with capacity 127.2 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:29.109706","level":"info","event":"25/09/23 17:47:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.2 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:29.286678","level":"info","event":"25/09/23 17:47:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:29.307147","level":"info","event":"25/09/23 17:47:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:29.359634","level":"info","event":"25/09/23 17:47:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:29.397938","level":"info","event":"25/09/23 17:47:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:29.513682","level":"info","event":"25/09/23 17:47:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.19.0.12,executor 0, partition 0, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:29.528868","level":"info","event":"25/09/23 17:47:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.19.0.12,executor 3, partition 1, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.120766","level":"info","event":"25/09/23 17:47:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 4580 ms on 172.19.0.12 (executor 3) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.139405","level":"info","event":"25/09/23 17:47:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4673 ms on 172.19.0.12 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.151312","level":"info","event":"25/09/23 17:47:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.173486","level":"info","event":"25/09/23 17:47:34 INFO DAGScheduler: ResultStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 5346 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.205293","level":"info","event":"25/09/23 17:47:34 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.208102","level":"info","event":"25/09/23 17:47:34 INFO TaskSchedulerImpl: Canceling stage 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.218913","level":"info","event":"25/09/23 17:47:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.229751","level":"info","event":"25/09/23 17:47:34 INFO DAGScheduler: Job 0 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 5849.777346 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.366964","level":"info","event":"25/09/23 17:47:34 INFO CodeGenerator: Code generated in 33.530743 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.404039","level":"info","event":"25/09/23 17:47:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.408054","level":"info","event":"25/09/23 17:47:34 INFO SparkContext: Created broadcast 1 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:34.872435","level":"info","event":"25/09/23 17:47:34 INFO CodeGenerator: Code generated in 131.196697 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.037889","level":"info","event":"25/09/23 17:47:35 INFO DAGScheduler: Registering RDD 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.102658","level":"info","event":"25/09/23 17:47:35 INFO DAGScheduler: Got map stage job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.111313","level":"info","event":"25/09/23 17:47:35 INFO DAGScheduler: Final stage: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.113871","level":"info","event":"25/09/23 17:47:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.116128","level":"info","event":"25/09/23 17:47:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.128653","level":"info","event":"25/09/23 17:47:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.209919","level":"info","event":"25/09/23 17:47:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 19.7 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.219589","level":"info","event":"25/09/23 17:47:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.223367","level":"info","event":"25/09/23 17:47:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.228792","level":"info","event":"25/09/23 17:47:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.229304","level":"info","event":"25/09/23 17:47:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.241262","level":"info","event":"25/09/23 17:47:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (172.19.0.12,executor 4, partition 0, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:35.241718","level":"info","event":"25/09/23 17:47:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3) (172.19.0.12,executor 5, partition 1, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.357726","level":"info","event":"25/09/23 17:47:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5119 ms on 172.19.0.12 (executor 5) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.412541","level":"info","event":"25/09/23 17:47:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5173 ms on 172.19.0.12 (executor 4) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.413517","level":"info","event":"25/09/23 17:47:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.424089","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 5273 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.426393","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.431134","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: running: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.431561","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: waiting: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.434471","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: failed: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.713183","level":"info","event":"25/09/23 17:47:40 INFO CodeGenerator: Code generated in 101.113098 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.825642","level":"info","event":"25/09/23 17:47:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.830057","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.830472","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.834572","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.834929","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.840334","level":"info","event":"25/09/23 17:47:40 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.900068","level":"info","event":"25/09/23 17:47:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.6 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:40.961110","level":"info","event":"25/09/23 17:47:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:41.000726","level":"info","event":"25/09/23 17:47:40 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:41.008254","level":"info","event":"25/09/23 17:47:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:41.008601","level":"info","event":"25/09/23 17:47:41 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:41.089428","level":"info","event":"25/09/23 17:47:41 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (172.19.0.12,executor 0, partition 0, NODE_LOCAL, 9635 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:41.427184","level":"info","event":"25/09/23 17:47:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.19.0.12:60202","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.330093","level":"info","event":"25/09/23 17:47:42 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 1291 ms on 172.19.0.12 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.330647","level":"info","event":"25/09/23 17:47:42 INFO TaskSchedulerImpl: Removed TaskSet 3.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.337682","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1457 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.353404","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.353744","level":"info","event":"25/09/23 17:47:42 INFO TaskSchedulerImpl: Canceling stage 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.354098","level":"info","event":"25/09/23 17:47:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.355422","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 1529.682068 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.405582","level":"info","event":"Tiempo JOIN normal: 25.75 segundos","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.696706","level":"info","event":"25/09/23 17:47:42 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.698884","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: Got job 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.699223","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.699471","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.700341","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.701645","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[14] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.711465","level":"info","event":"25/09/23 17:47:42 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.2 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.736657","level":"info","event":"25/09/23 17:47:42 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.763563","level":"info","event":"25/09/23 17:47:42 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.764108","level":"info","event":"25/09/23 17:47:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.764591","level":"info","event":"25/09/23 17:47:42 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.787604","level":"info","event":"25/09/23 17:47:42 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5) (172.19.0.12,executor 1, partition 0, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:42.798595","level":"info","event":"25/09/23 17:47:42 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 6) (172.19.0.12,executor 5, partition 1, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:43.330454","level":"info","event":"25/09/23 17:47:43 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 6) in 553 ms on 172.19.0.12 (executor 5) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.640115","level":"info","event":"25/09/23 17:47:45 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 2864 ms on 172.19.0.12 (executor 1) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.640705","level":"info","event":"25/09/23 17:47:45 INFO TaskSchedulerImpl: Removed TaskSet 4.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.641699","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 2936 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.642525","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.642918","level":"info","event":"25/09/23 17:47:45 INFO TaskSchedulerImpl: Canceling stage 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.643235","level":"info","event":"25/09/23 17:47:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.644214","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Job 3 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 2947.007326 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.678499","level":"info","event":"25/09/23 17:47:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.687318","level":"info","event":"25/09/23 17:47:45 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.918517","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Registering RDD 18 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.918882","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Got map stage job 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.919117","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Final stage: ShuffleMapStage 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.919730","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.921021","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.923492","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.930401","level":"info","event":"25/09/23 17:47:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 19.7 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.944965","level":"info","event":"25/09/23 17:47:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.949919","level":"info","event":"25/09/23 17:47:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.951352","level":"info","event":"25/09/23 17:47:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.952140","level":"info","event":"25/09/23 17:47:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.956976","level":"info","event":"25/09/23 17:47:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7) (172.19.0.12,executor 5, partition 0, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:45.958824","level":"info","event":"25/09/23 17:47:45 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 8) (172.19.0.12,executor 1, partition 1, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:46.314755","level":"info","event":"25/09/23 17:47:46 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 357 ms on 172.19.0.12 (executor 5) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.305020","level":"info","event":"25/09/23 17:47:47 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 8) in 1348 ms on 172.19.0.12 (executor 1) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.305652","level":"info","event":"25/09/23 17:47:47 INFO TaskSchedulerImpl: Removed TaskSet 5.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.306891","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: ShuffleMapStage 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1382 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.307210","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.307437","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: running: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.307648","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: waiting: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.310287","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: failed: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.371996","level":"info","event":"25/09/23 17:47:47 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.374463","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.374913","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: Final stage: ResultStage 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.375295","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.376320","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.377831","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.385837","level":"info","event":"25/09/23 17:47:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.6 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.400064","level":"info","event":"25/09/23 17:47:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.438523","level":"info","event":"25/09/23 17:47:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.444407","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.445070","level":"info","event":"25/09/23 17:47:47 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.458830","level":"info","event":"25/09/23 17:47:47 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 9) (172.19.0.12,executor 4, partition 0, NODE_LOCAL, 9635 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.715744","level":"info","event":"25/09/23 17:47:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.19.0.12:60236","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.984128","level":"info","event":"25/09/23 17:47:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 9) in 534 ms on 172.19.0.12 (executor 4) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.984579","level":"info","event":"25/09/23 17:47:47 INFO TaskSchedulerImpl: Removed TaskSet 7.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.986553","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: ResultStage 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 606 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.988429","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.989015","level":"info","event":"25/09/23 17:47:47 INFO TaskSchedulerImpl: Canceling stage 7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.989767","level":"info","event":"25/09/23 17:47:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:47.993514","level":"info","event":"25/09/23 17:47:47 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 618.370166 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.014116","level":"info","event":"Tiempo JOIN con broadcast: 5.61 segundos","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.427383","level":"info","event":"25/09/23 17:47:48 INFO CodeGenerator: Code generated in 37.305141 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.448672","level":"info","event":"25/09/23 17:47:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.450972","level":"info","event":"25/09/23 17:47:48 INFO DAGScheduler: Got job 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 6 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.451405","level":"info","event":"25/09/23 17:47:48 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.451833","level":"info","event":"25/09/23 17:47:48 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.452776","level":"info","event":"25/09/23 17:47:48 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.454495","level":"info","event":"25/09/23 17:47:48 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[25] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.459645","level":"info","event":"25/09/23 17:47:48 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.2 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.474540","level":"info","event":"25/09/23 17:47:48 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.503377","level":"info","event":"25/09/23 17:47:48 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.506485","level":"info","event":"25/09/23 17:47:48 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 8 (MapPartitionsRDD[25] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.508432","level":"info","event":"25/09/23 17:47:48 INFO TaskSchedulerImpl: Adding task set 8.0 with 6 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.514511","level":"info","event":"25/09/23 17:47:48 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (172.19.0.12,executor 4, partition 0, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.526542","level":"info","event":"25/09/23 17:47:48 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 11) (172.19.0.12,executor 2, partition 1, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.526793","level":"info","event":"25/09/23 17:47:48 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 12) (172.19.0.12,executor 5, partition 2, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.542567","level":"info","event":"25/09/23 17:47:48 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 13) (172.19.0.12,executor 0, partition 3, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.542849","level":"info","event":"25/09/23 17:47:48 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 14) (172.19.0.12,executor 3, partition 4, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:48.543050","level":"info","event":"25/09/23 17:47:48 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 15) (172.19.0.12,executor 1, partition 5, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:49.165633","level":"info","event":"25/09/23 17:47:49 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 653 ms on 172.19.0.12 (executor 4) (1/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:49.273874","level":"info","event":"25/09/23 17:47:49 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 15) in 742 ms on 172.19.0.12 (executor 1) (2/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:49.310070","level":"info","event":"25/09/23 17:47:49 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 12) in 793 ms on 172.19.0.12 (executor 5) (3/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:49.557584","level":"info","event":"25/09/23 17:47:49 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 13) in 1038 ms on 172.19.0.12 (executor 0) (4/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:49.561006","level":"info","event":"25/09/23 17:47:49 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 14) in 1030 ms on 172.19.0.12 (executor 3) (5/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.310016","level":"info","event":"25/09/23 17:47:52 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 11) in 3796 ms on 172.19.0.12 (executor 2) (6/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.310392","level":"info","event":"25/09/23 17:47:52 INFO TaskSchedulerImpl: Removed TaskSet 8.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.311184","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 3855 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.311639","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.311980","level":"info","event":"25/09/23 17:47:52 INFO TaskSchedulerImpl: Canceling stage 8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.312245","level":"info","event":"25/09/23 17:47:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.315100","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: Job 6 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 3866.016361 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.334690","level":"info","event":"25/09/23 17:47:52 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 251.0 B, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.343220","level":"info","event":"25/09/23 17:47:52 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.593482","level":"info","event":"25/09/23 17:47:52 INFO CodeGenerator: Code generated in 82.379927 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.625416","level":"info","event":"25/09/23 17:47:52 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.628154","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: Got job 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.628782","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.629089","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.629341","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.630842","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.635615","level":"info","event":"25/09/23 17:47:52 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 12.6 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.652819","level":"info","event":"25/09/23 17:47:52 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.657636","level":"info","event":"25/09/23 17:47:52 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.660610","level":"info","event":"25/09/23 17:47:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.662515","level":"info","event":"25/09/23 17:47:52 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.667036","level":"info","event":"25/09/23 17:47:52 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 16) (172.19.0.12,executor 2, partition 0, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.669093","level":"info","event":"25/09/23 17:47:52 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 17) (172.19.0.12,executor 3, partition 1, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:52.980740","level":"info","event":"25/09/23 17:47:52 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 16) in 314 ms on 172.19.0.12 (executor 2) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.066470","level":"info","event":"25/09/23 17:47:53 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 17) in 399 ms on 172.19.0.12 (executor 3) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.067859","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: ResultStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 435 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.068480","level":"info","event":"25/09/23 17:47:53 INFO TaskSchedulerImpl: Removed TaskSet 9.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.070236","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.070684","level":"info","event":"25/09/23 17:47:53 INFO TaskSchedulerImpl: Canceling stage 9","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.071067","level":"info","event":"25/09/23 17:47:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.071978","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Job 7 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 446.077896 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.137864","level":"info","event":"25/09/23 17:47:53 INFO CodeGenerator: Code generated in 30.274985 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.345088","level":"info","event":"25/09/23 17:47:53 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 158.6 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.352114","level":"info","event":"25/09/23 17:47:53 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.666387","level":"info","event":"25/09/23 17:47:53 INFO CodeGenerator: Code generated in 127.841661 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.687224","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Registering RDD 33 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.687702","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Got map stage job 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.688020","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Final stage: ShuffleMapStage 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.688298","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.689022","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.691042","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[33] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.697160","level":"info","event":"25/09/23 17:47:53 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 21.8 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.721730","level":"info","event":"25/09/23 17:47:53 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.723612","level":"info","event":"25/09/23 17:47:53 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.725856","level":"info","event":"25/09/23 17:47:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[33] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.726472","level":"info","event":"25/09/23 17:47:53 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.733063","level":"info","event":"25/09/23 17:47:53 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 18) (172.19.0.12,executor 4, partition 0, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:53.737239","level":"info","event":"25/09/23 17:47:53 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 19) (172.19.0.12,executor 3, partition 1, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.256528","level":"info","event":"25/09/23 17:47:55 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 18) in 1523 ms on 172.19.0.12 (executor 4) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.330486","level":"info","event":"25/09/23 17:47:55 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 19) in 1595 ms on 172.19.0.12 (executor 3) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.331124","level":"info","event":"25/09/23 17:47:55 INFO TaskSchedulerImpl: Removed TaskSet 10.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.331529","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: ShuffleMapStage 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1638 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.331811","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.332067","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: running: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.332313","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: waiting: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.332678","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: failed: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.401934","level":"info","event":"25/09/23 17:47:55 INFO CodeGenerator: Code generated in 38.56393 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.431874","level":"info","event":"25/09/23 17:47:55 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.434115","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: Got job 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.434591","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.434913","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.435144","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.437228","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[36] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.447056","level":"info","event":"25/09/23 17:47:55 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 13.6 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.466855","level":"info","event":"25/09/23 17:47:55 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.483579","level":"info","event":"25/09/23 17:47:55 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.508037","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[36] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.514951","level":"info","event":"25/09/23 17:47:55 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.520726","level":"info","event":"25/09/23 17:47:55 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 20) (172.19.0.12,executor 5, partition 0, NODE_LOCAL, 9635 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.645549","level":"info","event":"25/09/23 17:47:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.19.0.12:60218","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.959274","level":"info","event":"25/09/23 17:47:55 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 20) in 440 ms on 172.19.0.12 (executor 5) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.959892","level":"info","event":"25/09/23 17:47:55 INFO TaskSchedulerImpl: Removed TaskSet 12.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.962429","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: ResultStage 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 523 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.963089","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.963409","level":"info","event":"25/09/23 17:47:55 INFO TaskSchedulerImpl: Canceling stage 12","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.963792","level":"info","event":"25/09/23 17:47:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.964482","level":"info","event":"25/09/23 17:47:55 INFO DAGScheduler: Job 9 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 532.237912 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:55.986268","level":"info","event":"Tiempo JOIN con salting: 7.97 segundos","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.369979","level":"info","event":"25/09/23 17:47:56 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.374812","level":"info","event":"25/09/23 17:47:56 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.404057","level":"info","event":"25/09/23 17:47:56 INFO SparkUI: Stopped Spark web UI at http://619c5b104b4c:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.415946","level":"info","event":"25/09/23 17:47:56 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.417053","level":"info","event":"25/09/23 17:47:56 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.528933","level":"info","event":"25/09/23 17:47:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.663679","level":"info","event":"25/09/23 17:47:56 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.675637","level":"info","event":"25/09/23 17:47:56 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.750766","level":"info","event":"25/09/23 17:47:56 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.751308","level":"info","event":"25/09/23 17:47:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.808359","level":"info","event":"25/09/23 17:47:56 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.809622","level":"info","event":"25/09/23 17:47:56 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.816274","level":"info","event":"25/09/23 17:47:56 INFO ShutdownHookManager: Deleting directory /tmp/artifacts-ed0b02b4-58f1-44e0-904a-a5c09e5c293f","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.836252","level":"info","event":"25/09/23 17:47:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-7ff2a6f7-3335-4d69-9f17-207fbcdcdf3c/pyspark-4c1f5426-9385-4099-870b-bc9ca97bbe4c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.853011","level":"info","event":"25/09/23 17:47:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-7ff2a6f7-3335-4d69-9f17-207fbcdcdf3c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:56.875672","level":"info","event":"25/09/23 17:47:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-5bde75c1-e45f-4990-a517-6448ecd530c6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:47:57.214947Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:47:57.215794Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:47:57.216660Z","level":"info","event":"Task operator:<Task(SparkSubmitOperator): broadcast_salting>","chan":"stdout","logger":"task"}
