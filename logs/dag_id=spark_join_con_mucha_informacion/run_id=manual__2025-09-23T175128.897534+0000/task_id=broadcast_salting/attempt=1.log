{"timestamp":"2025-09-23T17:51:32.668199","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-23T17:51:32.668985","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/EJERCICIO_2.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-23T17:51:33.184296Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:51:33.185922Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:51:33.186377Z","level":"info","event":"Current task name:broadcast_salting","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:51:33.186773Z","level":"info","event":"Dag name:spark_join_con_mucha_informacion","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:51:33.187555","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-09-23T17:51:33.212604","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-09-23T17:51:33.215654","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.executor.memory=1g --conf spark.driver.memory=512m --conf spark.executor.cores=1 --conf spark.executor.instances=2 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_2.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:34.295248","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.754359","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.754725","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.754955","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.755223","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.755420","level":"info","event":"executorMemory          1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.755532","level":"info","event":"executorCores           1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.755622","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.755709","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.755814","level":"info","event":"driverMemory            512m","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.755993","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.756156","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.756316","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.756477","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.756641","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.756802","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.756939","level":"info","event":"numExecutors            2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.757171","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.757336","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.757521","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.757802","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.758046","level":"info","event":"primaryResource         file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_2.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.758279","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.758514","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.758688","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.758857","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.759016","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.759173","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.759325","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.759585","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.759747","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.759913","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.760283","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.760516","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.760707","level":"info","event":"(spark.executor.instances,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.760901","level":"info","event":"(spark.executor.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.761181","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.762229","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:37.762563","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.400151","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.400460","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.404950","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.405459","level":"info","event":"file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/Ejercicio_2.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.405743","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.406954","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.407278","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.407631","level":"info","event":"(spark.app.submitTime,1758649898301)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.407874","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.408057","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.408192","level":"info","event":"(spark.executor.instances,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.408349","level":"info","event":"(spark.executor.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.408520","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.408768","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.409220","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.409560","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.409780","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.415140","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:38.415447","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:41.862906","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:41.887821","level":"info","event":"25/09/23 17:51:41 INFO SparkContext: Running Spark version 4.0.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:41.900490","level":"info","event":"25/09/23 17:51:41 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:41.902868","level":"info","event":"25/09/23 17:51:41 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.078067","level":"info","event":"25/09/23 17:51:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.459857","level":"info","event":"25/09/23 17:51:42 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.460392","level":"info","event":"25/09/23 17:51:42 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.461150","level":"info","event":"25/09/23 17:51:42 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.463003","level":"info","event":"25/09/23 17:51:42 INFO SparkContext: Submitted application: SkewCartesianExample","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.504015","level":"info","event":"25/09/23 17:51:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.512699","level":"info","event":"25/09/23 17:51:42 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.517456","level":"info","event":"25/09/23 17:51:42 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.624175","level":"info","event":"25/09/23 17:51:42 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.626429","level":"info","event":"25/09/23 17:51:42 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.628088","level":"info","event":"25/09/23 17:51:42 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.629506","level":"info","event":"25/09/23 17:51:42 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:42.636438","level":"info","event":"25/09/23 17:51:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.159167","level":"info","event":"25/09/23 17:51:43 INFO Utils: Successfully started service 'sparkDriver' on port 37647.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.277147","level":"info","event":"25/09/23 17:51:43 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.308870","level":"info","event":"25/09/23 17:51:43 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.367171","level":"info","event":"25/09/23 17:51:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.369405","level":"info","event":"25/09/23 17:51:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.378476","level":"info","event":"25/09/23 17:51:43 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.458681","level":"info","event":"25/09/23 17:51:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-801dbc9e-f991-455f-ad58-02e032c44ded","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.531532","level":"info","event":"25/09/23 17:51:43 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:43.934167","level":"info","event":"25/09/23 17:51:43 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.127818","level":"info","event":"25/09/23 17:51:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.263319","level":"info","event":"25/09/23 17:51:44 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.263830","level":"info","event":"25/09/23 17:51:44 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.264563","level":"info","event":"25/09/23 17:51:44 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.265205","level":"info","event":"25/09/23 17:51:44 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.266271","level":"info","event":"25/09/23 17:51:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.570985","level":"info","event":"25/09/23 17:51:44 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.675369","level":"info","event":"25/09/23 17:51:44 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.11:7077 after 51 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.955741","level":"info","event":"25/09/23 17:51:44 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250923175144-0000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.980743","level":"info","event":"25/09/23 17:51:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33271.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.981014","level":"info","event":"25/09/23 17:51:44 INFO NettyBlockTransferService: Server created on 619c5b104b4c:33271","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:44.985484","level":"info","event":"25/09/23 17:51:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.032214","level":"info","event":"25/09/23 17:51:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 619c5b104b4c, 33271, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.050269","level":"info","event":"25/09/23 17:51:45 INFO BlockManagerMasterEndpoint: Registering block manager 619c5b104b4c:33271 with 127.2 MiB RAM, BlockManagerId(driver, 619c5b104b4c, 33271, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.059015","level":"info","event":"25/09/23 17:51:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 619c5b104b4c, 33271, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.062435","level":"info","event":"25/09/23 17:51:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 619c5b104b4c, 33271, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.153665","level":"info","event":"25/09/23 17:51:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923175144-0000/0 on worker-20250923175006-172.19.0.12-42359 (172.19.0.12:42359) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.156839","level":"info","event":"25/09/23 17:51:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923175144-0000/0 on hostPort 172.19.0.12:42359 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.162185","level":"info","event":"25/09/23 17:51:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923175144-0000/1 on worker-20250923175006-172.19.0.12-42359 (172.19.0.12:42359) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.166061","level":"info","event":"25/09/23 17:51:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923175144-0000/1 on hostPort 172.19.0.12:42359 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.166388","level":"info","event":"25/09/23 17:51:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923175144-0000/2 on worker-20250923175006-172.19.0.12-42359 (172.19.0.12:42359) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.166590","level":"info","event":"25/09/23 17:51:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923175144-0000/2 on hostPort 172.19.0.12:42359 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.166771","level":"info","event":"25/09/23 17:51:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923175144-0000/3 on worker-20250923175006-172.19.0.12-42359 (172.19.0.12:42359) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.176889","level":"info","event":"25/09/23 17:51:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923175144-0000/3 on hostPort 172.19.0.12:42359 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.177246","level":"info","event":"25/09/23 17:51:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923175144-0000/4 on worker-20250923175006-172.19.0.12-42359 (172.19.0.12:42359) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.177549","level":"info","event":"25/09/23 17:51:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923175144-0000/4 on hostPort 172.19.0.12:42359 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.177827","level":"info","event":"25/09/23 17:51:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250923175144-0000/5 on worker-20250923175006-172.19.0.12-42359 (172.19.0.12:42359) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.178026","level":"info","event":"25/09/23 17:51:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250923175144-0000/5 on hostPort 172.19.0.12:42359 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:45.926212","level":"info","event":"25/09/23 17:51:45 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:46.453675","level":"info","event":"25/09/23 17:51:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923175144-0000/4 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:46.484670","level":"info","event":"25/09/23 17:51:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923175144-0000/5 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:46.485031","level":"info","event":"25/09/23 17:51:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923175144-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:46.492412","level":"info","event":"25/09/23 17:51:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923175144-0000/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:46.501008","level":"info","event":"25/09/23 17:51:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923175144-0000/2 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:51:46.519105","level":"info","event":"25/09/23 17:51:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250923175144-0000/3 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:04.216040","level":"info","event":"25/09/23 17:52:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:04.277484","level":"info","event":"25/09/23 17:52:04 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:12.765310","level":"info","event":"Tiempo creación de datos: 9.63 segundos","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:20.290480","level":"info","event":"25/09/23 17:52:20 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:34110) with ID 4, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:21.285249","level":"info","event":"25/09/23 17:52:21 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:34094) with ID 2, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:21.918153","level":"info","event":"25/09/23 17:52:21 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:34126) with ID 5, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:22.424807","level":"info","event":"25/09/23 17:52:22 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:34120) with ID 1, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:22.498500","level":"info","event":"25/09/23 17:52:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:44899 with 434.4 MiB RAM, BlockManagerId(4, 172.19.0.12, 44899, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:22.665432","level":"info","event":"25/09/23 17:52:22 INFO CodeGenerator: Code generated in 1510.78389 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:22.968292","level":"info","event":"25/09/23 17:52:22 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:34132) with ID 0, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.431378","level":"info","event":"25/09/23 17:52:23 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:44049 with 434.4 MiB RAM, BlockManagerId(5, 172.19.0.12, 44049, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.489431","level":"info","event":"25/09/23 17:52:23 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.588016","level":"info","event":"25/09/23 17:52:23 INFO DAGScheduler: Got job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.600377","level":"info","event":"25/09/23 17:52:23 INFO DAGScheduler: Final stage: ResultStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.609471","level":"info","event":"25/09/23 17:52:23 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.625187","level":"info","event":"25/09/23 17:52:23 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.637237","level":"info","event":"25/09/23 17:52:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.642551","level":"info","event":"25/09/23 17:52:23 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:40931 with 434.4 MiB RAM, BlockManagerId(2, 172.19.0.12, 40931, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:23.855400","level":"info","event":"25/09/23 17:52:23 INFO MemoryStore: MemoryStore started with capacity 127.2 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.001068","level":"info","event":"25/09/23 17:52:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.2 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.128353","level":"info","event":"25/09/23 17:52:24 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.12:34148) with ID 3, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.316106","level":"info","event":"25/09/23 17:52:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:37641 with 434.4 MiB RAM, BlockManagerId(0, 172.19.0.12, 37641, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.400164","level":"info","event":"25/09/23 17:52:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.521737","level":"info","event":"25/09/23 17:52:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.615306","level":"info","event":"25/09/23 17:52:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:32961 with 434.4 MiB RAM, BlockManagerId(1, 172.19.0.12, 32961, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.664626","level":"info","event":"25/09/23 17:52:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.755188","level":"info","event":"25/09/23 17:52:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:24.997387","level":"info","event":"25/09/23 17:52:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.19.0.12,executor 4, partition 0, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:25.029235","level":"info","event":"25/09/23 17:52:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.19.0.12,executor 5, partition 1, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:25.464699","level":"info","event":"25/09/23 17:52:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.12:42531 with 434.4 MiB RAM, BlockManagerId(3, 172.19.0.12, 42531, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:29.755238","level":"info","event":"25/09/23 17:52:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 4743 ms on 172.19.0.12 (executor 5) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:29.777251","level":"info","event":"25/09/23 17:52:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4889 ms on 172.19.0.12 (executor 4) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:29.784082","level":"info","event":"25/09/23 17:52:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:29.806967","level":"info","event":"25/09/23 17:52:29 INFO DAGScheduler: ResultStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 6082 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:29.822552","level":"info","event":"25/09/23 17:52:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:29.824622","level":"info","event":"25/09/23 17:52:29 INFO TaskSchedulerImpl: Canceling stage 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:29.832686","level":"info","event":"25/09/23 17:52:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:29.848663","level":"info","event":"25/09/23 17:52:29 INFO DAGScheduler: Job 0 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 6362.135535 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:30.241301","level":"info","event":"25/09/23 17:52:30 INFO CodeGenerator: Code generated in 163.515509 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:30.348690","level":"info","event":"25/09/23 17:52:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:30.356223","level":"info","event":"25/09/23 17:52:30 INFO SparkContext: Created broadcast 1 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:30.916163","level":"info","event":"25/09/23 17:52:30 INFO CodeGenerator: Code generated in 230.157997 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.112276","level":"info","event":"25/09/23 17:52:31 INFO DAGScheduler: Registering RDD 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.134765","level":"info","event":"25/09/23 17:52:31 INFO DAGScheduler: Got map stage job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.147679","level":"info","event":"25/09/23 17:52:31 INFO DAGScheduler: Final stage: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.153834","level":"info","event":"25/09/23 17:52:31 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.157236","level":"info","event":"25/09/23 17:52:31 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.164809","level":"info","event":"25/09/23 17:52:31 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.304702","level":"info","event":"25/09/23 17:52:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 19.7 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.353240","level":"info","event":"25/09/23 17:52:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.356637","level":"info","event":"25/09/23 17:52:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.361322","level":"info","event":"25/09/23 17:52:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.362137","level":"info","event":"25/09/23 17:52:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.373197","level":"info","event":"25/09/23 17:52:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (172.19.0.12,executor 4, partition 0, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:31.374157","level":"info","event":"25/09/23 17:52:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3) (172.19.0.12,executor 0, partition 1, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:32.874252","level":"info","event":"25/09/23 17:52:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1506 ms on 172.19.0.12 (executor 4) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.085608","level":"info","event":"25/09/23 17:52:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 3714 ms on 172.19.0.12 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.086057","level":"info","event":"25/09/23 17:52:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.087345","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 3898 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.089119","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.090385","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: running: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.091593","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: waiting: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.092832","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: failed: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.176382","level":"info","event":"25/09/23 17:52:35 INFO CodeGenerator: Code generated in 29.980314 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.241720","level":"info","event":"25/09/23 17:52:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.246110","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.246561","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.247088","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.248397","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.253630","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.278910","level":"info","event":"25/09/23 17:52:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.6 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.303908","level":"info","event":"25/09/23 17:52:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.337227","level":"info","event":"25/09/23 17:52:35 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.337621","level":"info","event":"25/09/23 17:52:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.338067","level":"info","event":"25/09/23 17:52:35 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:35.364228","level":"info","event":"25/09/23 17:52:35 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (172.19.0.12,executor 1, partition 0, NODE_LOCAL, 9635 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:37.478029","level":"info","event":"25/09/23 17:52:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.19.0.12:34120","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.264856","level":"info","event":"25/09/23 17:52:39 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 3903 ms on 172.19.0.12 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.266112","level":"info","event":"25/09/23 17:52:39 INFO TaskSchedulerImpl: Removed TaskSet 3.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.267675","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 3995 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.274975","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.275482","level":"info","event":"25/09/23 17:52:39 INFO TaskSchedulerImpl: Canceling stage 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.275750","level":"info","event":"25/09/23 17:52:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.275965","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 4043.779913 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.326943","level":"info","event":"Tiempo JOIN normal: 26.57 segundos","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.743780","level":"info","event":"25/09/23 17:52:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.746143","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: Got job 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.746565","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.746847","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.748265","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.750282","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[14] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.756463","level":"info","event":"25/09/23 17:52:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.2 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.774514","level":"info","event":"25/09/23 17:52:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.827712","level":"info","event":"25/09/23 17:52:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.838381","level":"info","event":"25/09/23 17:52:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.846890","level":"info","event":"25/09/23 17:52:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.867215","level":"info","event":"25/09/23 17:52:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5) (172.19.0.12,executor 4, partition 0, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:39.886936","level":"info","event":"25/09/23 17:52:39 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 6) (172.19.0.12,executor 5, partition 1, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.123065","level":"info","event":"25/09/23 17:52:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 265 ms on 172.19.0.12 (executor 4) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.218578","level":"info","event":"25/09/23 17:52:40 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 6) in 352 ms on 172.19.0.12 (executor 5) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.219589","level":"info","event":"25/09/23 17:52:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.232047","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 470 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.232864","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.233193","level":"info","event":"25/09/23 17:52:40 INFO TaskSchedulerImpl: Canceling stage 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.233493","level":"info","event":"25/09/23 17:52:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.235970","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Job 3 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 491.617491 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.348016","level":"info","event":"25/09/23 17:52:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.363790","level":"info","event":"25/09/23 17:52:40 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.569515","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Registering RDD 18 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.570323","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Got map stage job 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.570725","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Final stage: ShuffleMapStage 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.570985","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.572055","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.573966","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.582673","level":"info","event":"25/09/23 17:52:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 19.7 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.597677","level":"info","event":"25/09/23 17:52:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.654629","level":"info","event":"25/09/23 17:52:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.682008","level":"info","event":"25/09/23 17:52:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.682428","level":"info","event":"25/09/23 17:52:40 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.694552","level":"info","event":"25/09/23 17:52:40 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7) (172.19.0.12,executor 2, partition 0, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:40.698252","level":"info","event":"25/09/23 17:52:40 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 8) (172.19.0.12,executor 0, partition 1, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:41.530141","level":"info","event":"25/09/23 17:52:41 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 8) in 831 ms on 172.19.0.12 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.584655","level":"info","event":"25/09/23 17:52:43 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 2898 ms on 172.19.0.12 (executor 2) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.585015","level":"info","event":"25/09/23 17:52:43 INFO TaskSchedulerImpl: Removed TaskSet 5.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.586478","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: ShuffleMapStage 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 3010 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.586861","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.587074","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: running: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.587266","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: waiting: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.587436","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: failed: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.622374","level":"info","event":"25/09/23 17:52:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.623906","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.624144","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: Final stage: ResultStage 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.624250","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.624702","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.625764","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.629837","level":"info","event":"25/09/23 17:52:43 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.6 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.640549","level":"info","event":"25/09/23 17:52:43 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.646326","level":"info","event":"25/09/23 17:52:43 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.646752","level":"info","event":"25/09/23 17:52:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.649762","level":"info","event":"25/09/23 17:52:43 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.656693","level":"info","event":"25/09/23 17:52:43 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 9) (172.19.0.12,executor 5, partition 0, NODE_LOCAL, 9635 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:43.791206","level":"info","event":"25/09/23 17:52:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.19.0.12:34126","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.162817","level":"info","event":"25/09/23 17:52:44 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 9) in 506 ms on 172.19.0.12 (executor 5) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.163287","level":"info","event":"25/09/23 17:52:44 INFO TaskSchedulerImpl: Removed TaskSet 7.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.165717","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: ResultStage 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 538 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.166761","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.167122","level":"info","event":"25/09/23 17:52:44 INFO TaskSchedulerImpl: Canceling stage 7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.167407","level":"info","event":"25/09/23 17:52:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.168483","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 545.520547 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.181301","level":"info","event":"Tiempo JOIN con broadcast: 4.85 segundos","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.623643","level":"info","event":"25/09/23 17:52:44 INFO CodeGenerator: Code generated in 69.744462 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.657223","level":"info","event":"25/09/23 17:52:44 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.659425","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: Got job 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 6 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.659877","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.660206","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.661257","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.662733","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[25] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.668641","level":"info","event":"25/09/23 17:52:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.2 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.688504","level":"info","event":"25/09/23 17:52:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.730343","level":"info","event":"25/09/23 17:52:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.731352","level":"info","event":"25/09/23 17:52:44 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 8 (MapPartitionsRDD[25] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.731675","level":"info","event":"25/09/23 17:52:44 INFO TaskSchedulerImpl: Adding task set 8.0 with 6 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.739373","level":"info","event":"25/09/23 17:52:44 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (172.19.0.12,executor 2, partition 0, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.743329","level":"info","event":"25/09/23 17:52:44 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 11) (172.19.0.12,executor 1, partition 1, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.745266","level":"info","event":"25/09/23 17:52:44 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 12) (172.19.0.12,executor 0, partition 2, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.753113","level":"info","event":"25/09/23 17:52:44 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 13) (172.19.0.12,executor 5, partition 3, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.753429","level":"info","event":"25/09/23 17:52:44 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 14) (172.19.0.12,executor 3, partition 4, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:44.756585","level":"info","event":"25/09/23 17:52:44 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 15) (172.19.0.12,executor 4, partition 5, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:45.450748","level":"info","event":"25/09/23 17:52:45 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 13) in 697 ms on 172.19.0.12 (executor 5) (1/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:45.483603","level":"info","event":"25/09/23 17:52:45 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 11) in 745 ms on 172.19.0.12 (executor 1) (2/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:45.599080","level":"info","event":"25/09/23 17:52:45 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 15) in 838 ms on 172.19.0.12 (executor 4) (3/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:45.879026","level":"info","event":"25/09/23 17:52:45 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 12) in 1134 ms on 172.19.0.12 (executor 0) (4/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:46.113945","level":"info","event":"25/09/23 17:52:46 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 1377 ms on 172.19.0.12 (executor 2) (5/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.171718","level":"info","event":"25/09/23 17:52:48 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 14) in 3419 ms on 172.19.0.12 (executor 3) (6/6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.172228","level":"info","event":"25/09/23 17:52:48 INFO TaskSchedulerImpl: Removed TaskSet 8.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.173267","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 3509 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.173695","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.173982","level":"info","event":"25/09/23 17:52:48 INFO TaskSchedulerImpl: Canceling stage 8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.174160","level":"info","event":"25/09/23 17:52:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.174750","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: Job 6 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 3517.24535 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.191296","level":"info","event":"25/09/23 17:52:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 251.0 B, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.199873","level":"info","event":"25/09/23 17:52:48 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.350144","level":"info","event":"25/09/23 17:52:48 INFO CodeGenerator: Code generated in 46.199412 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.371889","level":"info","event":"25/09/23 17:52:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.373481","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: Got job 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.373928","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.374233","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.374502","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.375671","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.380308","level":"info","event":"25/09/23 17:52:48 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 12.6 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.393812","level":"info","event":"25/09/23 17:52:48 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.397264","level":"info","event":"25/09/23 17:52:48 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.398877","level":"info","event":"25/09/23 17:52:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.399378","level":"info","event":"25/09/23 17:52:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.406285","level":"info","event":"25/09/23 17:52:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 16) (172.19.0.12,executor 5, partition 0, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.409305","level":"info","event":"25/09/23 17:52:48 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 17) (172.19.0.12,executor 3, partition 1, PROCESS_LOCAL, 9770 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:48.784139","level":"info","event":"25/09/23 17:52:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 16) in 378 ms on 172.19.0.12 (executor 5) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.032381","level":"info","event":"25/09/23 17:52:49 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 17) in 620 ms on 172.19.0.12 (executor 3) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.032823","level":"info","event":"25/09/23 17:52:49 INFO TaskSchedulerImpl: Removed TaskSet 9.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.042230","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: ResultStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 658 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.043939","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.047901","level":"info","event":"25/09/23 17:52:49 INFO TaskSchedulerImpl: Canceling stage 9","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.052026","level":"info","event":"25/09/23 17:52:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.062300","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Job 7 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 681.462216 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.139463","level":"info","event":"25/09/23 17:52:49 INFO CodeGenerator: Code generated in 31.335728 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.374537","level":"info","event":"25/09/23 17:52:49 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 158.6 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.379229","level":"info","event":"25/09/23 17:52:49 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.693798","level":"info","event":"25/09/23 17:52:49 INFO CodeGenerator: Code generated in 159.454315 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.726111","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Registering RDD 33 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.726530","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Got map stage job 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.726754","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Final stage: ShuffleMapStage 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.726956","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.727172","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.730659","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[33] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.738892","level":"info","event":"25/09/23 17:52:49 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 21.8 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.761999","level":"info","event":"25/09/23 17:52:49 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.766633","level":"info","event":"25/09/23 17:52:49 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.768408","level":"info","event":"25/09/23 17:52:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[33] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.768922","level":"info","event":"25/09/23 17:52:49 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.774608","level":"info","event":"25/09/23 17:52:49 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 18) (172.19.0.12,executor 0, partition 0, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:49.779001","level":"info","event":"25/09/23 17:52:49 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 19) (172.19.0.12,executor 3, partition 1, PROCESS_LOCAL, 9759 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:51.966747","level":"info","event":"25/09/23 17:52:51 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 18) in 2195 ms on 172.19.0.12 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.322740","level":"info","event":"25/09/23 17:52:52 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 19) in 2545 ms on 172.19.0.12 (executor 3) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.323328","level":"info","event":"25/09/23 17:52:52 INFO TaskSchedulerImpl: Removed TaskSet 10.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.324772","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: ShuffleMapStage 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 2593 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.325127","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.325364","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: running: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.325579","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: waiting: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.325827","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: failed: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.384316","level":"info","event":"25/09/23 17:52:52 INFO CodeGenerator: Code generated in 26.031112 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.403737","level":"info","event":"25/09/23 17:52:52 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.405192","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: Got job 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.405578","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.405849","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.406499","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.407922","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[36] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.411459","level":"info","event":"25/09/23 17:52:52 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 13.6 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.421933","level":"info","event":"25/09/23 17:52:52 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.434158","level":"info","event":"25/09/23 17:52:52 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.434559","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[36] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.434748","level":"info","event":"25/09/23 17:52:52 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.440741","level":"info","event":"25/09/23 17:52:52 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 20) (172.19.0.12,executor 3, partition 0, NODE_LOCAL, 9635 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.541639","level":"info","event":"25/09/23 17:52:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.19.0.12:34148","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.734569","level":"info","event":"25/09/23 17:52:52 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 20) in 295 ms on 172.19.0.12 (executor 3) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.735776","level":"info","event":"25/09/23 17:52:52 INFO TaskSchedulerImpl: Removed TaskSet 12.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.736359","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: ResultStage 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 327 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.736884","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.737777","level":"info","event":"25/09/23 17:52:52 INFO TaskSchedulerImpl: Canceling stage 12","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.738227","level":"info","event":"25/09/23 17:52:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.738500","level":"info","event":"25/09/23 17:52:52 INFO DAGScheduler: Job 9 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 333.278355 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:52.768768","level":"info","event":"Tiempo JOIN con salting: 8.59 segundos","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.012879","level":"info","event":"25/09/23 17:52:53 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.016335","level":"info","event":"25/09/23 17:52:53 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.033532","level":"info","event":"25/09/23 17:52:53 INFO SparkUI: Stopped Spark web UI at http://619c5b104b4c:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.041553","level":"info","event":"25/09/23 17:52:53 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.043186","level":"info","event":"25/09/23 17:52:53 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.132344","level":"info","event":"25/09/23 17:52:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.224951","level":"info","event":"25/09/23 17:52:53 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.254835","level":"info","event":"25/09/23 17:52:53 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.284371","level":"info","event":"25/09/23 17:52:53 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.317504","level":"info","event":"25/09/23 17:52:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.512333","level":"info","event":"25/09/23 17:52:53 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.514494","level":"info","event":"25/09/23 17:52:53 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.516257","level":"info","event":"25/09/23 17:52:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-7952819f-82de-4a30-a37d-9b90bb0dc0ca","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.537617","level":"info","event":"25/09/23 17:52:53 INFO ShutdownHookManager: Deleting directory /tmp/artifacts-038c4e11-a7b3-432f-b9dc-d8f6d9b61813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.566595","level":"info","event":"25/09/23 17:52:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-32cab170-67db-4ce8-b626-a55679ff1f2b","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.582221","level":"info","event":"25/09/23 17:52:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-32cab170-67db-4ce8-b626-a55679ff1f2b/pyspark-8b8aa6ca-89dd-4467-ac2b-e6a4c6e54723","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-23T17:52:53.872748Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:52:53.875297Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-23T17:52:53.880640Z","level":"info","event":"Task operator:<Task(SparkSubmitOperator): broadcast_salting>","chan":"stdout","logger":"task"}
