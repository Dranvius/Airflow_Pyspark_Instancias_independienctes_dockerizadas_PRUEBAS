{"timestamp":"2025-09-08T07:41:07.085309","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-08T07:41:07.086334","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/spark_wordcount_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-08T07:41:07.194323Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-08T07:41:07.195427Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-08T07:41:07.196195Z","level":"info","event":"Current task name:run_spark_test","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-08T07:41:07.196787Z","level":"info","event":"Dag name:spark_test_operator","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-08T07:41:07.198663","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-09-08T07:41:07.216033","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-09-08T07:41:07.219341","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --name arrow-spark --verbose --deploy-mode client /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:07.864692","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.074309","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.074599","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.074740","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.074942","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.075141","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.075281","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.075384","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.075551","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.075765","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.075960","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.076191","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.076642","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.077182","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.077505","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.077733","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.077921","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.078340","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.078734","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.078953","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.079152","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.079352","level":"info","event":"primaryResource         file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.079631","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.079877","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.080202","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.080407","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.080828","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.081078","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.081244","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.081438","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.081640","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.081764","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.081872","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.082042","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:12.082279","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.104840","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.106127","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.106944","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.107375","level":"info","event":"file:/opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.108650","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.117885","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.118364","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.118789","level":"info","event":"(spark.app.submitTime,1757317272933)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.119061","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.119281","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.119478","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.124859","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.125262","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.125547","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:13.125763","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:16.910332","level":"info","event":"INFO:WordCountApp:Iniciando la aplicación PySpark...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:18.589788","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:18.622165","level":"info","event":"25/09/08 07:41:18 INFO SparkContext: Running Spark version 4.0.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:18.638083","level":"info","event":"25/09/08 07:41:18 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:18.641878","level":"info","event":"25/09/08 07:41:18 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:18.920640","level":"info","event":"25/09/08 07:41:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.160950","level":"info","event":"25/09/08 07:41:19 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.162090","level":"info","event":"25/09/08 07:41:19 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.163348","level":"info","event":"25/09/08 07:41:19 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.168432","level":"info","event":"25/09/08 07:41:19 INFO SparkContext: Submitted application: WordCountApp","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.272373","level":"info","event":"25/09/08 07:41:19 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.286763","level":"info","event":"25/09/08 07:41:19 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.290953","level":"info","event":"25/09/08 07:41:19 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.456041","level":"info","event":"25/09/08 07:41:19 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.459087","level":"info","event":"25/09/08 07:41:19 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.460495","level":"info","event":"25/09/08 07:41:19 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.461595","level":"info","event":"25/09/08 07:41:19 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:19.473259","level":"info","event":"25/09/08 07:41:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:20.602994","level":"info","event":"25/09/08 07:41:20 INFO Utils: Successfully started service 'sparkDriver' on port 36309.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:20.701996","level":"info","event":"25/09/08 07:41:20 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:20.745621","level":"info","event":"25/09/08 07:41:20 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:20.874009","level":"info","event":"25/09/08 07:41:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:20.876026","level":"info","event":"25/09/08 07:41:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:20.892548","level":"info","event":"25/09/08 07:41:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:21.043481","level":"info","event":"25/09/08 07:41:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3836e6d4-9025-47bd-9423-e1fc997599a7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:21.190861","level":"info","event":"25/09/08 07:41:21 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:21.759833","level":"info","event":"25/09/08 07:41:21 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:22.021038","level":"info","event":"25/09/08 07:41:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:22.280248","level":"info","event":"25/09/08 07:41:22 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:22.280659","level":"info","event":"25/09/08 07:41:22 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:22.281312","level":"info","event":"25/09/08 07:41:22 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:22.282214","level":"info","event":"25/09/08 07:41:22 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:22.283307","level":"info","event":"25/09/08 07:41:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:23.002995","level":"info","event":"25/09/08 07:41:22 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:23.334325","level":"info","event":"25/09/08 07:41:23 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.2:7077 after 169 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.262557","level":"info","event":"25/09/08 07:41:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250908074123-0000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.297191","level":"info","event":"25/09/08 07:41:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38259.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.298200","level":"info","event":"25/09/08 07:41:24 INFO NettyBlockTransferService: Server created on 619c5b104b4c:38259","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.315755","level":"info","event":"25/09/08 07:41:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.383321","level":"info","event":"25/09/08 07:41:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 619c5b104b4c, 38259, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.403118","level":"info","event":"25/09/08 07:41:24 INFO BlockManagerMasterEndpoint: Registering block manager 619c5b104b4c:38259 with 434.4 MiB RAM, BlockManagerId(driver, 619c5b104b4c, 38259, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.412419","level":"info","event":"25/09/08 07:41:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 619c5b104b4c, 38259, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.415781","level":"info","event":"25/09/08 07:41:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 619c5b104b4c, 38259, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.701695","level":"info","event":"25/09/08 07:41:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250908074123-0000/0 on worker-20250908054224-172.19.0.4-43799 (172.19.0.4:43799) with 8 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:24.711323","level":"info","event":"25/09/08 07:41:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20250908074123-0000/0 on hostPort 172.19.0.4:43799 with 8 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:25.216665","level":"info","event":"25/09/08 07:41:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:27.158105","level":"info","event":"25/09/08 07:41:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250908074123-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:39.678640","level":"info","event":"25/09/08 07:41:39 INFO SparkContext: Starting job: collect at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:28","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:39.924936","level":"info","event":"25/09/08 07:41:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:24) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:39.977325","level":"info","event":"25/09/08 07:41:39 INFO DAGScheduler: Got job 0 (collect at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:28) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:39.988415","level":"info","event":"25/09/08 07:41:39 INFO DAGScheduler: Final stage: ResultStage 1 (collect at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:28)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.000731","level":"info","event":"25/09/08 07:41:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.018815","level":"info","event":"25/09/08 07:41:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.062512","level":"info","event":"25/09/08 07:41:40 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:24), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.410689","level":"info","event":"25/09/08 07:41:40 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.500167","level":"info","event":"25/09/08 07:41:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.3 KiB, free 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.705902","level":"info","event":"25/09/08 07:41:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.796799","level":"info","event":"25/09/08 07:41:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.870079","level":"info","event":"25/09/08 07:41:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:24) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:40.919137","level":"info","event":"25/09/08 07:41:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:44.903925","level":"info","event":"25/09/08 07:41:44 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.4:44260) with ID 0, ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:45.941658","level":"info","event":"25/09/08 07:41:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.4:44567 with 434.4 MiB RAM, BlockManagerId(0, 172.19.0.4, 44567, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:46.398372","level":"info","event":"25/09/08 07:41:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.19.0.4,executor 0, partition 0, PROCESS_LOCAL, 9720 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:46.418167","level":"info","event":"25/09/08 07:41:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.19.0.4,executor 0, partition 1, PROCESS_LOCAL, 9734 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.062388","level":"info","event":"25/09/08 07:41:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8779 ms on 172.19.0.4 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.075260","level":"info","event":"25/09/08 07:41:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8660 ms on 172.19.0.4 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.077841","level":"info","event":"25/09/08 07:41:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.113898","level":"info","event":"25/09/08 07:41:55 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 54593","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.143123","level":"info","event":"25/09/08 07:41:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:24) finished in 14987 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.145947","level":"info","event":"25/09/08 07:41:55 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.149554","level":"info","event":"25/09/08 07:41:55 INFO DAGScheduler: running: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.163253","level":"info","event":"25/09/08 07:41:55 INFO DAGScheduler: waiting: HashSet(ResultStage 1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.163638","level":"info","event":"25/09/08 07:41:55 INFO DAGScheduler: failed: HashSet()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.191890","level":"info","event":"25/09/08 07:41:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:28), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.242292","level":"info","event":"25/09/08 07:41:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.3 KiB, free 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.273614","level":"info","event":"25/09/08 07:41:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.277115","level":"info","event":"25/09/08 07:41:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.291382","level":"info","event":"25/09/08 07:41:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:28) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.292783","level":"info","event":"25/09/08 07:41:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.323695","level":"info","event":"25/09/08 07:41:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (172.19.0.4,executor 0, partition 0, NODE_LOCAL, 9453 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.329537","level":"info","event":"25/09/08 07:41:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3) (172.19.0.4,executor 0, partition 1, NODE_LOCAL, 9453 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:55.798106","level":"info","event":"25/09/08 07:41:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.19.0.4:44260","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.808532","level":"info","event":"25/09/08 07:41:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1482 ms on 172.19.0.4 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.811604","level":"info","event":"25/09/08 07:41:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1496 ms on 172.19.0.4 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.812655","level":"info","event":"25/09/08 07:41:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.831259","level":"info","event":"25/09/08 07:41:56 INFO DAGScheduler: ResultStage 1 (collect at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:28) finished in 1600 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.848802","level":"info","event":"25/09/08 07:41:56 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.852416","level":"info","event":"25/09/08 07:41:56 INFO TaskSchedulerImpl: Canceling stage 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.856996","level":"info","event":"25/09/08 07:41:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.876527","level":"info","event":"25/09/08 07:41:56 INFO DAGScheduler: Job 0 finished: collect at /opt/airflow/pyspark_instancia_pruebas/pyspark_instancia_pruebas/test_pyspark.py:28, took 17198.117335 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.933441","level":"info","event":"INFO:WordCountApp:Palabra: mundo - Conteo: 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.933709","level":"info","event":"INFO:WordCountApp:Palabra: es - Conteo: 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.933928","level":"info","event":"INFO:WordCountApp:Palabra: genial - Conteo: 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.934137","level":"info","event":"INFO:WordCountApp:Palabra: vez - Conteo: 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.934342","level":"info","event":"INFO:WordCountApp:Palabra: hola - Conteo: 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.934560","level":"info","event":"INFO:WordCountApp:Palabra: spark - Conteo: 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.935734","level":"info","event":"INFO:WordCountApp:Palabra: otra - Conteo: 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.940110","level":"info","event":"INFO:WordCountApp:Finalizando la aplicación PySpark...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.944441","level":"info","event":"25/09/08 07:41:56 INFO SparkContext: SparkContext is stopping with exitCode 0 from stop at NativeMethodAccessorImpl.java:0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:56.982598","level":"info","event":"25/09/08 07:41:56 INFO SparkUI: Stopped Spark web UI at http://619c5b104b4c:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.010589","level":"info","event":"25/09/08 07:41:57 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.012369","level":"info","event":"25/09/08 07:41:57 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.128733","level":"info","event":"25/09/08 07:41:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.214312","level":"info","event":"25/09/08 07:41:57 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.216301","level":"info","event":"25/09/08 07:41:57 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.267658","level":"info","event":"25/09/08 07:41:57 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.290620","level":"info","event":"25/09/08 07:41:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.341936","level":"info","event":"25/09/08 07:41:57 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:57.829550","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:58.108676","level":"info","event":"25/09/08 07:41:58 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:58.110018","level":"info","event":"25/09/08 07:41:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-24e2f886-2cb6-45f2-b1c5-07155df3a61b","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:58.117339","level":"info","event":"25/09/08 07:41:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-692f6b55-3446-48d9-82b6-e83cb0c724b0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:58.128446","level":"info","event":"25/09/08 07:41:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-24e2f886-2cb6-45f2-b1c5-07155df3a61b/pyspark-e82ba4d2-4472-4981-8460-127e1674af8a","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-09-08T07:41:58.315459Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-08T07:41:58.316087Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-08T07:41:58.316724Z","level":"info","event":"Task operator:<Task(SparkSubmitOperator): run_spark_test>","chan":"stdout","logger":"task"}
